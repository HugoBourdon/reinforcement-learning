{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class 4: Deep Q Networks.**\n",
    "\n",
    "1. [Everything you need to know](#everything)\n",
    "1. [Reminder](#reminder)\n",
    "1. <a href=\"#sec1\">Environments</a>\n",
    "    1. <a href=\"#sec1.1\">Cartpole</a>\n",
    "    2. <a href=\"#sec1.2\">Cartpole swing-up</a>\n",
    "    3. <a href=\"#sec1.3\">Pong</a>\n",
    "2. <a href=\"#sec2\">Value Iteration as a sequence of Supervized Learning problems</a>\n",
    "3. <a href=\"#sec3\">Experience Replay</a>\n",
    "4. <a href=\"#sec4\">A deep Q-network</a>\n",
    "5. <a href=\"#sec5\">Making DQN more efficient</a>\n",
    "    1. <a href=\"#sec5.1\">Changing the optimizer\n",
    "    2. <a href=\"#sec5.2\">Several gradient steps\n",
    "    3. <a href=\"#sec5.3\">Target network</a>\n",
    "    4. <a href=\"#sec5.4\">Error clipping</a>\n",
    "6. <a href=\"#sec6\">Metrics</a>\n",
    "7. <a href=\"#sec7\">DQN on image-based tasks</a>\n",
    "8. <a href=\"#sec8\">Going further</a>\n",
    "9. [Challenge](#challenge)\n",
    "    1. [Bicycle](#bicycle)\n",
    "    2. [Structured Treatment Interruptions](#sti)\n",
    "    3. [Your turn to play](#turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous classes we saw that one could replace the model-based value iteration process by an approximate value iteration one. When the approximation is done by performing stochastic approximation, we obtain the $Q$ learning algorithm. We saw it was straightforward to extend this to use experience replay memories and batch stochastic gradient descent. In this class, we combine the stochastic gradient descent approach with replay memories and represent $Q$ as a neural network. This yields the Deep Q-Networks algorithm.\n",
    "\n",
    "There are few new concepts in this class compared to previous ones. Mainly, what we do is bring neural networks into the framework we have previously built. Therefore, this class is aimed at more practice. For this purpose, we start by introducing a set of [environments](#sec1) to illustrate further developments. Then we will start from Value Iteration and repeat the thought process of the previous classes, introduce [stochastic gradient descent](#sec2), [experience replay](#sec3) and reach the [DQN algorithm](#sec4). The end of the class is an [open challenge](#challenge) on several difficult benchmarks.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Prerequisites:**\n",
    "- Stochastic Approximation for Approximate Value Iteration\n",
    "- Deep Learning\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with this quote:\n",
    "\n",
    "> The idea that we learn by interacting with our environment is probably the first to occur to us when we think about the nature of learning. When an infant plays, waves its arms, or looks about, it has no explicit teacher, but it does have a direct sensorimotor connection to its environment. Exercising this connection produces a wealth of information about cause and effect, about the consequences of actions, and about what to do in order to achieve goals. Throughout our lives, such interactions are undoubtedly a major source of knowledge about our environment and ourselves. Whether we are learning to drive a car or to hold a conversation, we are acutely aware of how our environment responds to what we do, and we seek to influence what happens through our behavior. Learning from interaction is a foundational idea underlying nearly all theories of learning and intelligence. (Richard S. Sutton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything you need to know\n",
    "\n",
    "Everything you should remember after this session.<br>\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "- Deep Q-Networks is an approximate value iteration algorithm that uses experience replay and stochastic gradient descent to learn $Q^*$ as a neural network. The DQN itself is the neural network.\n",
    "- DQN pseudo-code\n",
    "         state = init()\n",
    "         loop:\n",
    "            action = greedy_action(DQN) or random_action()\n",
    "            new_state, reward = step(state, action)\n",
    "            replay_memory.add(state, action, reward, new_state)\n",
    "            minibatch = replay_memory.sample(minibatch_size)\n",
    "            X_train = Y_train = []\n",
    "            for (s,a,r,s') in minibatch:\n",
    "                Q  = DQN.predict(s)\n",
    "                Q' = DQN.predict(s')\n",
    "                if non-terminal(s'): \n",
    "                    update = r + gamma * max(Q')    \n",
    "                else:  \n",
    "                    update = r\n",
    "                Q[a] = update\n",
    "                X_train.add(s)\n",
    "                Y_train.add(Q)\n",
    "            DQN.train_one_step(X_train,Y_train)\n",
    "            state = new_state\n",
    "- The pseudo-code above can be improved by introducing a second network $Q^-$ called *target network*, that is used to compute `update` in the pseudo-code above. Every $C$ steps $Q^-$ is replaced by the learned network.\n",
    "- Common improvements to DQN involve using a Huber loss and tuning the optimizer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder\n",
    "\n",
    "- Value Iteration builds the sequence $Q_{n+1} = T^* Q_n$ that converges to $Q^*$\n",
    "- Given a set of samples $\\{(s,a,r,s')\\}$, one can perform stochastic gradient descent on the loss $L_n(Q) = \\|Q - T^* Q_n \\|_2$ and thus approximate the sequence of value functions from value iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec1\"></a> Environments\n",
    "\n",
    "In this session, we will work with three different environments:\n",
    "- CartPole\n",
    "- A modified version of CartPole\n",
    "- Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license] in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (0.17.3)\n",
      "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'accept-rom-license'\u001b[0m\n",
      "Requirement already satisfied: scipy in /home/hugo/.local/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.7.3)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.6.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/hugo/.local/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.21.4)\n",
      "Requirement already satisfied: future in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[accept-rom-license]) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "#from gym import logger\n",
    "!pip install gym[accept-rom-license]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license] in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (0.17.3)\n",
      "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'accept-rom-license'\u001b[0m\n",
      "Requirement already satisfied: scipy in /home/hugo/.local/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.7.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/hugo/.local/lib/python3.7/site-packages (from gym[accept-rom-license]) (1.21.4)\n",
      "Requirement already satisfied: future in /home/hugo/anaconda3/envs/rl/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[accept-rom-license]) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#logger.set_level(gym.logger.DISABLED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec1.1></a>CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "cartpole = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [OpenAI Gym website](https://gym.openai.com/envs/CartPole-v0/)\n",
    "\n",
    "> A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware that, as most Gym environments, CartPole has a maximum number of steps before necessarily returning `done=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartpole._max_episode_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cartpole is represented by a state $s = (x, \\dot{x}, \\theta, \\dot{\\theta})$ with :\n",
    "  - $x$ the position of the cartpole along the x-axis\n",
    "  - $\\theta$ the angle of the pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
      "{'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}\n"
     ]
    }
   ],
   "source": [
    "print(cartpole.action_space)\n",
    "print(cartpole.observation_space)\n",
    "print(cartpole.env.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "x = cartpole.reset()\n",
    "#cartpole.render()\n",
    "for i in range(2000):\n",
    "    _, _, d, _ = cartpole.step(np.random.randint(2))\n",
    "    #cartpole.render()\n",
    "    if d:\n",
    "        print(i)\n",
    "        break\n",
    "    time.sleep(cartpole.tau) # not actually real-time, just for readability\n",
    "\n",
    "cartpole.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec1.2></a>CartPole Swing-up\n",
    "\n",
    "The idea here is to keep the same environment, but instead of learning how to stabilize it around the unstable equilibrium point, we'd like to learn to swing it up. Here are the changes:\n",
    "- `reset` now puts the pole pointing down. The initial state is $(0,0,\\pi,0)$ plus a vector of four uniformly random values in [-0.05,0.05].\n",
    "- `step` now returns `done=True` when the cart leaves the $x\\in [-2.4,2.4]$ interval or when the pole swings faster than $4\\pi$ radians per second.\n",
    "- the reward is still +1 for keeping the pole within 12 degrees of the vertical, it is 0 for all other time steps and -10 for swinging too fast or exiting the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.swingup import CartPoleSwingUp\n",
    "swingup = CartPoleSwingUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = swingup.reset()\n",
    "#swingup.render()\n",
    "\n",
    "for i in range(1000):\n",
    "    _, _, d, _ = swingup.step(np.random.randint(2))\n",
    "    #swingup.render()\n",
    "    if d:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "swingup.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec1.3></a>Pong\n",
    "\n",
    "Let's build an agent that learns to play Pong, one of the [Atari games](https://github.com/openai/gym/blob/master/gym/envs/atari/atari_env.py) in Gym (originally in the [Arcade Learning Environment](https://github.com/mgbellemare/Arcade-Learning-Environment)). You might want to try different games later on (like the popular Breakout game for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/envs/flatland-rl/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n",
      "A.L.E: Arcade Learning Environment (version +978d2ce)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "pong = gym.make('Pong-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the environment's description.\n",
    "> Maximize your score in the Atari 2600 game Pong. In this environment, the observation is an RGB image of the screen, which is an array of shape (210, 160, 3). Each action is repeatedly performed for a duration of k frames, where k is uniformly sampled from $\\{2, 3, 4\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]], (210, 160, 3), uint8)\n",
      "(210, 160, 3)\n",
      "0\n",
      "255\n",
      "Discrete(6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(pong.observation_space)\n",
    "print(pong.observation_space.shape)\n",
    "print(np.min(pong.observation_space.low))\n",
    "print(np.max(pong.observation_space.high))\n",
    "print(pong.action_space)\n",
    "#help(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "x = pong.reset()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercise:** What is the number of possible states? Why is this not an MDP? What would one need to turn this back into an MDP?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <a href=\"#Pong-theory\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"Pong-theory\" class=\"collapse\">\n",
    "\n",
    "One frame is a $210\\times 160$ RGB image with a 256 color palette, so the set of all possible frames has size $256^{210 \\times 160 \\times 3} \\sim 10^{242579}$. That's a little too many for an efficient enumeration. Of course, most of the possible images will never occur in a Breakout game and the true state space is actually a much smaller subset of the full set of possible images. Nevertheless, unless we provide a large engineering effort in describing the state space with few variables (which would be contradictory of our goal of a \"human-level\" AI) we will need to automatically discover some structure in the state sampled data.\n",
    "\n",
    "This is not an MDP because the transition dynamics do not respect Markov's property. The probability of transitioning from $s_t$ to $s_{t+1}$ is *not* independent of previous states. The problem here is that a single frame of the game does not reflect the velocity of the ball.\n",
    "\n",
    "To recover Markov's property one could simply stack a few frames together in the state space.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 18 buttons on the Atari controller. However not all games use all buttons. Our interface to Pong specifies 6 possible actions:\n",
    "- 0 NOOP (no operation)\n",
    "- 1 FIRE (press fire button, doesn't do anything in Pong)\n",
    "- 2 RIGHT (actually moves the paddle up in Pong)\n",
    "- 3 LEFT (actually moves the paddle left in Pong)\n",
    "- 4 UP (moves the paddle upwards)\n",
    "- 5 DOWN (moves the paddle downwards)\n",
    "\n",
    "The available actions in Pong go up to the 6th action for naming consistency (UP and DOWN), but the four first actions are not really useful.\n",
    "\n",
    "Also, for an unknown reason, the game does not start until the 20th frame (but always starts automatically, pressing FIRE does not change anything).\n",
    "\n",
    "The frame rate is 60Hz.\n",
    "\n",
    "To avoid confusion between the 6 actions allowed by Gym, let's build a wrapper around our environment, with only 2 possible actions (\"0\" for UP and \"1\" for DOWN) and a downscaled observation space. Unless you're curious and want to dig in the code, you can simply run the following cells and just use the resulting environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/envs/flatland-rl/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n",
      "A.L.E: Arcade Learning Environment (version +978d2ce)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "from environments.pongwrapper import PongWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong = PongWrapper(noop_max=0,\n",
    "                   frame_skip=4,\n",
    "                   terminal_on_life_loss=True,\n",
    "                   grayscale_obs=True,\n",
    "                   scale_obs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (84, 84), min = 0.34117648, max = 0.9137255, dtype = float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trying a random agent in Pong\n",
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pong.reset()\n",
    "#pong.render()\n",
    "for i in range(60):\n",
    "    a = np.random.randint(2)\n",
    "    x, r, _, _ = pong.step(a)\n",
    "    #pong.render()\n",
    "    #print('\\r', \"reward\", r, end=\"\")\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "pong.close()\n",
    "print(\"shape: \", x.shape, \", min = \", x.min(), \", max = \", x.max(), \", dtype = \", x.dtype, sep='')\n",
    "plt.imshow(x, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=sec2></a>Value Iteration as a sequence of Supervized Learning problems\n",
    "\n",
    "Recall the Value Iteration update: $Q_{n+1} = T^*Q_n$.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercise:**  \n",
    "Suppose $Q_{n+1}$ is a parametric function $Q(s,a;\\theta_{n+1})$ with parameters $\\theta_{n+1}$. We want to approximate $T^*Q_n$ with $Q(s,a;\\theta_{n+1})$. Write the loss function minimized for this regression problem.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <a href=\"#ValueIteration\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"ValueIteration\" class=\"collapse\">\n",
    "\n",
    "Let's start over from the beginning. We want to find:\n",
    "$$\\pi^*(s) = \\arg\\max_{\\pi} \\mathbb{E}_{\\left(r_t\\right)_{t\\in \\mathbb{N}}} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\ \\Big| \\ s, \\pi \\right], \\ \\forall s\\in S.$$\n",
    "\n",
    "We have seen this was equivalent to finding the optimal value function $Q^*$:\n",
    "$$Q^*(s,a) = \\max_{\\pi} \\mathbb{E}_{\\left(r_t\\right)_{t\\in \\mathbb{N}}} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\ \\Big| \\  s,a, \\pi \\right], \\ \\forall (s,a) \\in S\\times A.$$\n",
    "\n",
    "And we have established that $Q^*$ was the only solution to Bellman's optimality equation:\n",
    "$$Q(s,a) = \\mathbb{E}_{s' \\sim p(\\cdot|s,a)} \\left[r(s,a,s') + \\gamma \\max_{a'} Q(s',a')\\right].$$\n",
    "\n",
    "By writing $T^*$ Bellman's optimality operator, we have, by definition:\n",
    "$$(T^*Q)(s,a) = \\mathbb{E}_{s' \\sim p(\\cdot|s,a)} \\left[r(s,a,s') + \\gamma \\max_{a'} Q(s',a')\\right].$$\n",
    "\n",
    "And thus, $Q^*$ is the only solution to $Q=T^*Q$.\n",
    "\n",
    "It appears $T^*$ is a contraction mapping on the $\\mathcal{F}(S\\times A,\\mathbb{R})$ space. Value Iteration exploits this property to build the sequence $Q_{n+1} = T^*Q_n$ which converges to $Q^*$.\n",
    "\n",
    "Let's now suppose that $Q_n$ is a function approximator, whose parameters are $\\theta_n$. We shall write $Q_n(s,a) = Q(s,a;\\theta_n)$. Then building $\\theta_{n+1}$ knowing $\\theta_n$ is the regression problem that minimizes the loss:\n",
    "\\begin{gather}\n",
    "L_n(\\theta) = \\left\\| y_n(s,a) - Q(s,a;\\theta) \\right\\|,\\\\\n",
    "\\textrm{with } y_n(s,a) = \\mathbb{E}_{s' \\sim p(\\cdot|s,a)} \\left[r(s,a,s') + \\gamma \\max_{a'} Q(s',a';\\theta_{n})\\right].\n",
    "\\end{gather}\n",
    "\n",
    "If this loss can be optimized and goes to zero, then we have found the true $Q_{n+1}$. If not, then we have found an approximation of it in the norm used to define $L_n$.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercise:**  \n",
    "Use the L2 norm in the loss of the regression problem above, then write the gradient of the loss with respect to the regressor's parameters. Use this to introduce a stochastic gradient descent method to find $\\theta_{n+1}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <a href=\"#VILoss\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"VILoss\" class=\"collapse\">\n",
    "\n",
    "Our loss becomes:\n",
    "\\begin{gather}\n",
    "L_n(\\theta) = \\frac{1}{2} \\mathbb{E}_{(s,a) \\sim \\rho(\\cdot)}\\left[ \\big( y_n(s,a) - Q(s,a;\\theta) \\big)^2 \\right],\\\\\n",
    "\\textrm{with } y_n(s,a) = \\mathbb{E}_{s' \\sim p(\\cdot|s,a)} \\left[r(s,a,s') + \\gamma \\max_{a'} Q(s',a';\\theta_{n})\\right].\n",
    "\\end{gather}\n",
    "\n",
    "In the expression above, $\\rho$ is a distribution over the state-action space. Often, it is considered to be the behavior distribution, that is the distribution of samples under the current behavior policy, like $\\epsilon$-greedy. Note that this choice is debatable.\n",
    "\n",
    "So the gradient of this loss is:\n",
    "\\begin{gather}\n",
    "\\nabla_\\theta L_n(\\theta) = \\mathbb{E}_{(s,a) \\sim \\rho(\\cdot)}\\left[ \\big( y_n(s,a) - Q(s,a;\\theta) \\big) \\nabla_\\theta Q(s,a;\\theta) \\right]\\\\\n",
    "\\textrm{with } y_n(s,a) = \\mathbb{E}_{s' \\sim p(\\cdot|s,a)} \\left[r(s,a,s') + \\gamma \\max_{a'} Q(s',a';\\theta_{n})\\right].\n",
    "\\end{gather}\n",
    "\n",
    "And when we wrap all this together:\n",
    "$$\\nabla_\\theta L_n(\\theta) = \\mathbb{E}_{(s,a) \\sim \\rho(\\cdot)}\\left[ \\left( \\mathbb{E}_{s' \\sim p(\\cdot|s,a)} \\left[r(s,a,s') + \\gamma \\max_{a'} Q(s',a';\\theta_{n})\\right] - Q(s,a;\\theta) \\right) \\nabla_\\theta Q(s,a;\\theta) \\right]$$\n",
    "\n",
    "$$\\nabla_\\theta L_n(\\theta) = \\mathbb{E}_{\\substack{(s,a) \\sim \\rho(\\cdot)\\\\ s' \\sim p(\\cdot|s,a)}}\\left[ \\left( r(s,a,s') + \\gamma \\max_{a'} Q(s',a';\\theta_{n}) - Q(s,a;\\theta) \\right) \\nabla_\\theta Q(s,a;\\theta) \\right]$$\n",
    "\n",
    "We can build a Monte Carlo estimate of this gradient, given a mini-batch of independently and identically drawn samples $\\left\\{\\left(s_i,a_i,r_i,s'_i\\right)\\right\\}_{i\\in [1,B]}$, with $(s,a) \\sim \\rho(\\cdot)$ and $s' \\sim p(\\cdot | s,a)$:\n",
    "$$\\nabla_\\theta L_n(\\theta) \\approx d_n(\\theta) = \\sum_{i=1}^B \\left[ \\left( r_i + \\gamma \\max_{a'} Q(s_i',a';\\theta_{n}) - Q(s_i,a_i;\\theta) \\right) \\nabla_\\theta Q(s_i,a_i;\\theta) \\right].$$\n",
    "\n",
    "The stochastic gradient descent procedure builds a sequence of parameter values $\\theta_k$ such that:\n",
    "$$\\theta_{k+1} \\leftarrow \\theta_{k} - \\alpha d_n(\\theta_{k})$$\n",
    "\n",
    "By repeating such gradient steps, one progressively minimizes $L_n(\\theta)$ and finds $\\theta_{n+1}$.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important remark:**  \n",
    "\n",
    "In the update above, if the mini-batch contains a single element, the 1-sample update is precisely that of Q-learning! Then, in Q-learning, the new loss $L_{n+1}$ is defined and the process is repeated. Consequently, there is a new loss function at each time step.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercise:** can you spot the (subtle but essential) difference with Q-learning?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <a href=\"#DifferenceQL\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"DifferenceQL\" class=\"collapse\">\n",
    "\n",
    "Recall Q-learning. The update was indeed the same, except that at any time step the mini-batch's single element was not sampled independently from the previous minibatch! Indeed, $s'$ from the previous time step becomes $s$ for the current time step. So the successive mini-batches' elements are not drawn iid.\n",
    "\n",
    "That's a key difference that questions the foundation of Q-learning in itself.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=sec3></a>Experience Replay\n",
    "\n",
    "To recover the independence assumption between samples, we can introduce the mechanism of [*Experience Replay*](http://www.incompleteideas.net/lin-92.pdf) by storing past samples into a *Replay Memory*. When samples a required for a mini-batch gradient update, the samples are collected uniformly from the replay memory, thus mimicking an (almost) independent draw according to $\\rho(\\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Design a class for the replay memory of the cart-pole example(s). Limit the size of this memory (via a FIFO mechanism) to $10^6$ samples (adapt this number to your computer's RAM). Test it by running a random policy for $2\\cdot 10^6$ time steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "cartpole = gym.make('CartPole-v1')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity\n",
    "        self.data = []\n",
    "        self.index = 0\n",
    "    \n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data)<self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s,a,r,s_,d)\n",
    "        self.index = (self.index+1)%self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.data,batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 2000000/2000000 [00:47<00:00, 42278.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 14354.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0.02010922, -0.02354709, -0.03467668,  0.03625622], dtype=float32), 1, 1.0, array([ 0.01963828,  0.17205453, -0.03395155, -0.2671627 ], dtype=float32), False), (array([-0.03985136, -0.04753263,  0.04485668, -0.03361673], dtype=float32), 1, 1.0, array([-0.04080201,  0.14691831,  0.04418434, -0.3118163 ], dtype=float32), False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/RL5_exercise1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Replay buffer class\n",
    "import random\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.data, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Testing insertion in the ReplayBuffer class\n",
    "from tqdm import trange\n",
    "replay_buffer_size = int(1e6)\n",
    "nb_samples = int(2e6)\n",
    "\n",
    "memory = ReplayBuffer(replay_buffer_size)\n",
    "state = cartpole.reset()\n",
    "for _ in trange(nb_samples):\n",
    "    action = cartpole.action_space.sample()\n",
    "    next_state, reward, done, _ = cartpole.step(action)\n",
    "    memory.append(state, action, reward, next_state, done)\n",
    "    if done:\n",
    "        state = cartpole.reset()\n",
    "    else:\n",
    "        state = next_state\n",
    "\n",
    "print(len(memory))\n",
    "\n",
    "# Testing sampling in the ReplayBuffer class\n",
    "nb_batches = int(1e4)\n",
    "batch_size = 50\n",
    "import random\n",
    "\n",
    "for _ in trange(nb_batches):\n",
    "    batch = memory.sample(batch_size)\n",
    "\n",
    "print(memory.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Know your data structures!**\n",
    "\n",
    "Taking the time to think about what makes a good replay buffer may save you hours of puzzled head-banging. It is important to know what you expect from your replay buffer to choose the right data structure.\n",
    "\n",
    "Common mistake: we need a fixed sized memory, that works like a FIFO structure, so let's pick a deque. That sounds fair, deques (in Python) have a fixed maximum size and constant time insertion at the beginning and the end. BUT they also have $O(n)$ access time which means that for large replay buffers, sampling a minibatch may take forever.\n",
    "\n",
    "Here, what we really need is a fixed-size FIFO, with $O(1)$ insertion at the end and $O(1)$ access.\n",
    "\n",
    "This should motivate the choices made in the replay buffer class above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=sec4></a>A deep Q-network\n",
    "\n",
    "The term Deep Q-Network was coined by the (now historical) paper **[Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602)** by Mnih et al. (2013) that put forward the main ideas we develop here. All those were later popularized by DeepMind's paper in Nature **[Human-level control through deep reinforcement learning](https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning)** by Mnih et al. (2015).\n",
    "\n",
    "Let's design a (deep) neural network that will serve as a function approximator for $Q(s,a;\\theta)$. \n",
    "\n",
    "<img src=\"img/dqlas.png\" height=\"15%\" width=\"15%\"></img>\n",
    "\n",
    "Note that since we're going to have to compute $\\max_a Q(s,a)$ it is preferable to avoid running as many passes through the network as there are actions. Therefore, instead of the network structure above, we will prefer to use the one below.\n",
    "\n",
    "<img src=\"img/dqls.png\" height=\"30%\" width=\"30%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Declare a neural network for our $Q$ function. For the CartPole task, you can use a simple network with 2 hidden layers and 16 neurons on each layer. For the SwingUp task, go up to 50 neurons per layer. For Pong and the other environments... well wait a minute, we'll get to it later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "cartpole = gym.make('CartPole-v1')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DQN = torch.nn.Sequential(nn.Linear(4,16),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(16,16),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(16,2)).to(device)\n",
    "\n",
    "DGN_swingup = torch.nn.Sequential(nn.Linear(4,50),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(50,50),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(50,2)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL5_exercise2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "state_dim = cartpole.observation_space.shape[0]\n",
    "n_action = cartpole.action_space.n \n",
    "nb_neurons=24\n",
    "\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost there. Now you can implement the algorithm that:\n",
    "- takes $\\epsilon$-greedy actions with respect to $Q$\n",
    "- stores samples in the replay buffer\n",
    "- at each interaction step with the environment, draws a mini-batch, computes the target values for each $(s,a)$ and takes a gradient step.\n",
    "- repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Write this algorithm's pseudo-code, then proceed with your implementation, using the network and replay buffer you defined in the previous cells.\n",
    "</div>\n",
    "\n",
    "You can take inspiration from the algorithm on page 5 of **[Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <a href=\"#DQNpseudocode\" data-toggle=\"collapse\"><b>Answer:</b></a><br>\n",
    "<div id=\"DQNpseudocode\" class=\"collapse\">\n",
    "\n",
    "         state = init()\n",
    "         loop:\n",
    "            action = greedy_action(DQN) or random_action()\n",
    "            new_state, reward = step(state, action)\n",
    "            replay_memory.add(state, action, reward, new_state)\n",
    "            minibatch = replay_memory.sample(minibatch_size)\n",
    "            X_train = Y_train = []\n",
    "            for (s,a,r,s') in minibatch:\n",
    "                Q  = DQN.predict(s)\n",
    "                Q' = DQN.predict(s')\n",
    "                if non-terminal(s'): \n",
    "                    update = r + gamma * max(Q')    \n",
    "                else:  \n",
    "                    update = r\n",
    "                Q[a] = update\n",
    "                X_train.add(s)\n",
    "                Y_train.add(Q)\n",
    "            DQN.train_one_step(X_train,Y_train)\n",
    "            state = new_state\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with the implementation. This series of exercises break it down into small steps.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "It will actually be useful to have separate torch.Tensor for the each element type in the sampled minibatch.  \n",
    "That is one Tensor for a minibatch of states, another for actions, etc.\n",
    "Let's redefine the sample function of our replay buffer class to that end.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL5_exercise3.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(lambda x:torch.Tensor(x).to(device), list(zip(*batch))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Define a utility function that computes the greedy action from a DQN and a batch of states.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL5_exercise4.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import torch\n",
    "\n",
    "def greedy_action(network, state):\n",
    "    #device = \"cuda\" if next(network.parameters()).is_cuda else \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        Q = network(torch.Tensor(state).unsqueeze(0).to(device))\n",
    "        return torch.argmax(Q).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Write a class that keeps a replay buffer as internal attribute and implements the pseudo-code you wrote earlier.  \n",
    "Here are a few tips:\n",
    "- To ensure exploration, take a constant $\\epsilon_{max}$ value during $\\tau_{delay}$ time steps, then substract $\\epsilon_{step}$ from $\\epsilon$ at every time step until you reach time $\\tau_{period}$.\n",
    "- A common optimizer (instead of plain SGD) is RMSprop.\n",
    "- Assume the interaction with the environment will be episodic. After each training episode store the episode's cumulated return for monitoring.\n",
    "\n",
    "Write your class but don't run this code just yet!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL5_exercise5.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DQN_agent:\n",
    "    def __init__(self, config, model):\n",
    "        self.gamma = config['gamma']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.nb_actions = config['nb_actions']\n",
    "        self.memory = ReplayBuffer(config['buffer_size'])\n",
    "        self.epsilon_max = config['epsilon_max']\n",
    "        self.epsilon_min = config['epsilon_min']\n",
    "        self.epsilon_stop = config['epsilon_decay_period']\n",
    "        self.epsilon_delay = config['epsilon_delay_decay']\n",
    "        self.epsilon_step = (self.epsilon_max-self.epsilon_min)/self.epsilon_stop\n",
    "        self.total_steps = 0\n",
    "        self.model = model \n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
    "            QYmax = self.model(Y).max(1)[0].detach()\n",
    "            update = torch.addcmul(R, self.gamma, 1-D, QYmax)\n",
    "            QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
    "            loss = self.criterion(QXA, update.unsqueeze(1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def train(self, env, max_episode):\n",
    "        episode_return = []\n",
    "        episode = 0\n",
    "        episode_cum_reward = 0\n",
    "        state = env.reset()\n",
    "        epsilon = self.epsilon_max\n",
    "        step = 0\n",
    "\n",
    "        while episode < max_episode:\n",
    "            # update epsilon\n",
    "            if step > self.epsilon_delay:\n",
    "                epsilon = max(self.epsilon_min, epsilon-self.epsilon_step)\n",
    "\n",
    "            # select epsilon-greedy action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.randint(self.nb_actions)\n",
    "            else:\n",
    "                action = greedy_action(self.model, state)\n",
    "\n",
    "            # step\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            self.memory.append(state, action, reward, next_state, done)\n",
    "            episode_cum_reward += reward\n",
    "\n",
    "            # train\n",
    "            self.gradient_step()\n",
    "\n",
    "            # next transition\n",
    "            step += 1\n",
    "            if done:\n",
    "                episode += 1\n",
    "                print(\"Episode \", '{:3d}'.format(episode), \n",
    "                      \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                      \", batch size \", '{:5d}'.format(len(self.memory)), \n",
    "                      \", episode return \", '{:4.1f}'.format(episode_cum_reward),\n",
    "                      sep='')\n",
    "                state = env.reset()\n",
    "                episode_return.append(episode_cum_reward)\n",
    "                episode_cum_reward = 0\n",
    "            else:\n",
    "                state = next_state\n",
    "\n",
    "        return episode_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Train for 200 episodes on CartPole, with a learning rate of $0.001$, abatch size of $20$, $\\gamma=0.95$ and a replay buffer of maximum $1000000$ samples. Take $\\epsilon_{max}=1$, $\\epsilon_{min=0.01}$, $\\tau_{delay}=20$ and $\\tau_{period}=1000$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode   1, epsilon   1.00, batch size    16, episode return 16.0\n",
      "Episode   2, epsilon   0.97, batch size    52, episode return 36.0\n",
      "Episode   3, epsilon   0.93, batch size    93, episode return 41.0\n",
      "Episode   4, epsilon   0.92, batch size   106, episode return 13.0\n",
      "Episode   5, epsilon   0.82, batch size   199, episode return 93.0\n",
      "Episode   6, epsilon   0.77, batch size   255, episode return 56.0\n",
      "Episode   7, epsilon   0.72, batch size   300, episode return 45.0\n",
      "Episode   8, epsilon   0.70, batch size   323, episode return 23.0\n",
      "Episode   9, epsilon   0.68, batch size   348, episode return 25.0\n",
      "Episode  10, epsilon   0.63, batch size   397, episode return 49.0\n",
      "Episode  11, epsilon   0.57, batch size   455, episode return 58.0\n",
      "Episode  12, epsilon   0.41, batch size   617, episode return 162.0\n",
      "Episode  13, epsilon   0.39, batch size   637, episode return 20.0\n",
      "Episode  14, epsilon   0.02, batch size  1008, episode return 371.0\n",
      "Episode  15, epsilon   0.01, batch size  1210, episode return 202.0\n",
      "Episode  16, epsilon   0.01, batch size  1387, episode return 177.0\n",
      "Episode  17, epsilon   0.01, batch size  1563, episode return 176.0\n",
      "Episode  18, epsilon   0.01, batch size  1723, episode return 160.0\n",
      "Episode  19, epsilon   0.01, batch size  1914, episode return 191.0\n",
      "Episode  20, epsilon   0.01, batch size  2109, episode return 195.0\n",
      "Episode  21, epsilon   0.01, batch size  2284, episode return 175.0\n",
      "Episode  22, epsilon   0.01, batch size  2462, episode return 178.0\n",
      "Episode  23, epsilon   0.01, batch size  2649, episode return 187.0\n",
      "Episode  24, epsilon   0.01, batch size  2829, episode return 180.0\n",
      "Episode  25, epsilon   0.01, batch size  2987, episode return 158.0\n",
      "Episode  26, epsilon   0.01, batch size  3140, episode return 153.0\n",
      "Episode  27, epsilon   0.01, batch size  3334, episode return 194.0\n",
      "Episode  28, epsilon   0.01, batch size  3508, episode return 174.0\n",
      "Episode  29, epsilon   0.01, batch size  3682, episode return 174.0\n",
      "Episode  30, epsilon   0.01, batch size  3839, episode return 157.0\n",
      "Episode  31, epsilon   0.01, batch size  4009, episode return 170.0\n",
      "Episode  32, epsilon   0.01, batch size  4221, episode return 212.0\n",
      "Episode  33, epsilon   0.01, batch size  4384, episode return 163.0\n",
      "Episode  34, epsilon   0.01, batch size  4537, episode return 153.0\n",
      "Episode  35, epsilon   0.01, batch size  4746, episode return 209.0\n",
      "Episode  36, epsilon   0.01, batch size  4928, episode return 182.0\n",
      "Episode  37, epsilon   0.01, batch size  5113, episode return 185.0\n",
      "Episode  38, epsilon   0.01, batch size  5265, episode return 152.0\n",
      "Episode  39, epsilon   0.01, batch size  5452, episode return 187.0\n",
      "Episode  40, epsilon   0.01, batch size  5613, episode return 161.0\n",
      "Episode  41, epsilon   0.01, batch size  5761, episode return 148.0\n",
      "Episode  42, epsilon   0.01, batch size  5948, episode return 187.0\n",
      "Episode  43, epsilon   0.01, batch size  6129, episode return 181.0\n",
      "Episode  44, epsilon   0.01, batch size  6335, episode return 206.0\n",
      "Episode  45, epsilon   0.01, batch size  6516, episode return 181.0\n",
      "Episode  46, epsilon   0.01, batch size  6793, episode return 277.0\n",
      "Episode  47, epsilon   0.01, batch size  6952, episode return 159.0\n",
      "Episode  48, epsilon   0.01, batch size  7112, episode return 160.0\n",
      "Episode  49, epsilon   0.01, batch size  7318, episode return 206.0\n",
      "Episode  50, epsilon   0.01, batch size  7485, episode return 167.0\n",
      "Episode  51, epsilon   0.01, batch size  7626, episode return 141.0\n",
      "Episode  52, epsilon   0.01, batch size  7787, episode return 161.0\n",
      "Episode  53, epsilon   0.01, batch size  7947, episode return 160.0\n",
      "Episode  54, epsilon   0.01, batch size  8125, episode return 178.0\n",
      "Episode  55, epsilon   0.01, batch size  8290, episode return 165.0\n",
      "Episode  56, epsilon   0.01, batch size  8479, episode return 189.0\n",
      "Episode  57, epsilon   0.01, batch size  8652, episode return 173.0\n",
      "Episode  58, epsilon   0.01, batch size  8856, episode return 204.0\n",
      "Episode  59, epsilon   0.01, batch size  9001, episode return 145.0\n",
      "Episode  60, epsilon   0.01, batch size  9172, episode return 171.0\n",
      "Episode  61, epsilon   0.01, batch size  9347, episode return 175.0\n",
      "Episode  62, epsilon   0.01, batch size  9491, episode return 144.0\n",
      "Episode  63, epsilon   0.01, batch size  9658, episode return 167.0\n",
      "Episode  64, epsilon   0.01, batch size  9856, episode return 198.0\n",
      "Episode  65, epsilon   0.01, batch size 10020, episode return 164.0\n",
      "Episode  66, epsilon   0.01, batch size 10204, episode return 184.0\n",
      "Episode  67, epsilon   0.01, batch size 10364, episode return 160.0\n",
      "Episode  68, epsilon   0.01, batch size 10503, episode return 139.0\n",
      "Episode  69, epsilon   0.01, batch size 10668, episode return 165.0\n",
      "Episode  70, epsilon   0.01, batch size 10825, episode return 157.0\n",
      "Episode  71, epsilon   0.01, batch size 10993, episode return 168.0\n",
      "Episode  72, epsilon   0.01, batch size 11154, episode return 161.0\n",
      "Episode  73, epsilon   0.01, batch size 11301, episode return 147.0\n",
      "Episode  74, epsilon   0.01, batch size 11472, episode return 171.0\n",
      "Episode  75, epsilon   0.01, batch size 11608, episode return 136.0\n",
      "Episode  76, epsilon   0.01, batch size 11790, episode return 182.0\n",
      "Episode  77, epsilon   0.01, batch size 11939, episode return 149.0\n",
      "Episode  78, epsilon   0.01, batch size 12082, episode return 143.0\n",
      "Episode  79, epsilon   0.01, batch size 12231, episode return 149.0\n",
      "Episode  80, epsilon   0.01, batch size 12394, episode return 163.0\n",
      "Episode  81, epsilon   0.01, batch size 12538, episode return 144.0\n",
      "Episode  82, epsilon   0.01, batch size 12673, episode return 135.0\n",
      "Episode  83, epsilon   0.01, batch size 12804, episode return 131.0\n",
      "Episode  84, epsilon   0.01, batch size 12944, episode return 140.0\n",
      "Episode  85, epsilon   0.01, batch size 13122, episode return 178.0\n",
      "Episode  86, epsilon   0.01, batch size 13282, episode return 160.0\n",
      "Episode  87, epsilon   0.01, batch size 13443, episode return 161.0\n",
      "Episode  88, epsilon   0.01, batch size 13640, episode return 197.0\n",
      "Episode  89, epsilon   0.01, batch size 13791, episode return 151.0\n",
      "Episode  90, epsilon   0.01, batch size 13953, episode return 162.0\n",
      "Episode  91, epsilon   0.01, batch size 14137, episode return 184.0\n",
      "Episode  92, epsilon   0.01, batch size 14303, episode return 166.0\n",
      "Episode  93, epsilon   0.01, batch size 14453, episode return 150.0\n",
      "Episode  94, epsilon   0.01, batch size 14653, episode return 200.0\n",
      "Episode  95, epsilon   0.01, batch size 14803, episode return 150.0\n",
      "Episode  96, epsilon   0.01, batch size 14952, episode return 149.0\n",
      "Episode  97, epsilon   0.01, batch size 15106, episode return 154.0\n",
      "Episode  98, epsilon   0.01, batch size 15493, episode return 387.0\n",
      "Episode  99, epsilon   0.01, batch size 15662, episode return 169.0\n",
      "Episode 100, epsilon   0.01, batch size 15870, episode return 208.0\n",
      "Episode 101, epsilon   0.01, batch size 16063, episode return 193.0\n",
      "Episode 102, epsilon   0.01, batch size 16212, episode return 149.0\n",
      "Episode 103, epsilon   0.01, batch size 16383, episode return 171.0\n",
      "Episode 104, epsilon   0.01, batch size 16560, episode return 177.0\n",
      "Episode 105, epsilon   0.01, batch size 16748, episode return 188.0\n",
      "Episode 106, epsilon   0.01, batch size 16931, episode return 183.0\n",
      "Episode 107, epsilon   0.01, batch size 17103, episode return 172.0\n",
      "Episode 108, epsilon   0.01, batch size 17275, episode return 172.0\n",
      "Episode 109, epsilon   0.01, batch size 17439, episode return 164.0\n",
      "Episode 110, epsilon   0.01, batch size 17594, episode return 155.0\n",
      "Episode 111, epsilon   0.01, batch size 17810, episode return 216.0\n",
      "Episode 112, epsilon   0.01, batch size 17963, episode return 153.0\n",
      "Episode 113, epsilon   0.01, batch size 18125, episode return 162.0\n",
      "Episode 114, epsilon   0.01, batch size 18295, episode return 170.0\n",
      "Episode 115, epsilon   0.01, batch size 18448, episode return 153.0\n",
      "Episode 116, epsilon   0.01, batch size 18632, episode return 184.0\n",
      "Episode 117, epsilon   0.01, batch size 18802, episode return 170.0\n",
      "Episode 118, epsilon   0.01, batch size 18962, episode return 160.0\n",
      "Episode 119, epsilon   0.01, batch size 19148, episode return 186.0\n",
      "Episode 120, epsilon   0.01, batch size 19327, episode return 179.0\n",
      "Episode 121, epsilon   0.01, batch size 19473, episode return 146.0\n",
      "Episode 122, epsilon   0.01, batch size 19631, episode return 158.0\n",
      "Episode 123, epsilon   0.01, batch size 19798, episode return 167.0\n",
      "Episode 124, epsilon   0.01, batch size 19973, episode return 175.0\n",
      "Episode 125, epsilon   0.01, batch size 20116, episode return 143.0\n",
      "Episode 126, epsilon   0.01, batch size 20264, episode return 148.0\n",
      "Episode 127, epsilon   0.01, batch size 20428, episode return 164.0\n",
      "Episode 128, epsilon   0.01, batch size 20595, episode return 167.0\n",
      "Episode 129, epsilon   0.01, batch size 20749, episode return 154.0\n",
      "Episode 130, epsilon   0.01, batch size 20897, episode return 148.0\n",
      "Episode 131, epsilon   0.01, batch size 21077, episode return 180.0\n",
      "Episode 132, epsilon   0.01, batch size 21241, episode return 164.0\n",
      "Episode 133, epsilon   0.01, batch size 21400, episode return 159.0\n",
      "Episode 134, epsilon   0.01, batch size 21549, episode return 149.0\n",
      "Episode 135, epsilon   0.01, batch size 21714, episode return 165.0\n",
      "Episode 136, epsilon   0.01, batch size 21872, episode return 158.0\n",
      "Episode 137, epsilon   0.01, batch size 22043, episode return 171.0\n",
      "Episode 138, epsilon   0.01, batch size 22220, episode return 177.0\n",
      "Episode 139, epsilon   0.01, batch size 22394, episode return 174.0\n",
      "Episode 140, epsilon   0.01, batch size 22563, episode return 169.0\n",
      "Episode 141, epsilon   0.01, batch size 22718, episode return 155.0\n",
      "Episode 142, epsilon   0.01, batch size 22863, episode return 145.0\n",
      "Episode 143, epsilon   0.01, batch size 23080, episode return 217.0\n",
      "Episode 144, epsilon   0.01, batch size 23245, episode return 165.0\n",
      "Episode 145, epsilon   0.01, batch size 23419, episode return 174.0\n",
      "Episode 146, epsilon   0.01, batch size 23602, episode return 183.0\n",
      "Episode 147, epsilon   0.01, batch size 23777, episode return 175.0\n",
      "Episode 148, epsilon   0.01, batch size 23998, episode return 221.0\n",
      "Episode 149, epsilon   0.01, batch size 24179, episode return 181.0\n",
      "Episode 150, epsilon   0.01, batch size 24329, episode return 150.0\n",
      "Episode 151, epsilon   0.01, batch size 24502, episode return 173.0\n",
      "Episode 152, epsilon   0.01, batch size 24660, episode return 158.0\n",
      "Episode 153, epsilon   0.01, batch size 24826, episode return 166.0\n",
      "Episode 154, epsilon   0.01, batch size 24983, episode return 157.0\n",
      "Episode 155, epsilon   0.01, batch size 25129, episode return 146.0\n",
      "Episode 156, epsilon   0.01, batch size 25267, episode return 138.0\n",
      "Episode 157, epsilon   0.01, batch size 25419, episode return 152.0\n",
      "Episode 158, epsilon   0.01, batch size 25582, episode return 163.0\n",
      "Episode 159, epsilon   0.01, batch size 25764, episode return 182.0\n",
      "Episode 160, epsilon   0.01, batch size 25912, episode return 148.0\n",
      "Episode 161, epsilon   0.01, batch size 26068, episode return 156.0\n",
      "Episode 162, epsilon   0.01, batch size 26227, episode return 159.0\n",
      "Episode 163, epsilon   0.01, batch size 26398, episode return 171.0\n",
      "Episode 164, epsilon   0.01, batch size 26563, episode return 165.0\n",
      "Episode 165, epsilon   0.01, batch size 26726, episode return 163.0\n",
      "Episode 166, epsilon   0.01, batch size 26886, episode return 160.0\n",
      "Episode 167, epsilon   0.01, batch size 27058, episode return 172.0\n",
      "Episode 168, epsilon   0.01, batch size 27221, episode return 163.0\n",
      "Episode 169, epsilon   0.01, batch size 27365, episode return 144.0\n",
      "Episode 170, epsilon   0.01, batch size 27519, episode return 154.0\n",
      "Episode 171, epsilon   0.01, batch size 27673, episode return 154.0\n",
      "Episode 172, epsilon   0.01, batch size 27840, episode return 167.0\n",
      "Episode 173, epsilon   0.01, batch size 28002, episode return 162.0\n",
      "Episode 174, epsilon   0.01, batch size 28183, episode return 181.0\n",
      "Episode 175, epsilon   0.01, batch size 28345, episode return 162.0\n",
      "Episode 176, epsilon   0.01, batch size 28493, episode return 148.0\n",
      "Episode 177, epsilon   0.01, batch size 28653, episode return 160.0\n",
      "Episode 178, epsilon   0.01, batch size 28804, episode return 151.0\n",
      "Episode 179, epsilon   0.01, batch size 28962, episode return 158.0\n",
      "Episode 180, epsilon   0.01, batch size 29128, episode return 166.0\n",
      "Episode 181, epsilon   0.01, batch size 29304, episode return 176.0\n",
      "Episode 182, epsilon   0.01, batch size 29484, episode return 180.0\n",
      "Episode 183, epsilon   0.01, batch size 29639, episode return 155.0\n",
      "Episode 184, epsilon   0.01, batch size 29835, episode return 196.0\n",
      "Episode 185, epsilon   0.01, batch size 29979, episode return 144.0\n",
      "Episode 186, epsilon   0.01, batch size 30129, episode return 150.0\n",
      "Episode 187, epsilon   0.01, batch size 30283, episode return 154.0\n",
      "Episode 188, epsilon   0.01, batch size 30444, episode return 161.0\n",
      "Episode 189, epsilon   0.01, batch size 30606, episode return 162.0\n",
      "Episode 190, epsilon   0.01, batch size 30798, episode return 192.0\n",
      "Episode 191, epsilon   0.01, batch size 31017, episode return 219.0\n",
      "Episode 192, epsilon   0.01, batch size 31181, episode return 164.0\n",
      "Episode 193, epsilon   0.01, batch size 31334, episode return 153.0\n",
      "Episode 194, epsilon   0.01, batch size 31499, episode return 165.0\n",
      "Episode 195, epsilon   0.01, batch size 31649, episode return 150.0\n",
      "Episode 196, epsilon   0.01, batch size 31792, episode return 143.0\n",
      "Episode 197, epsilon   0.01, batch size 32004, episode return 212.0\n",
      "Episode 198, epsilon   0.01, batch size 32158, episode return 154.0\n",
      "Episode 199, epsilon   0.01, batch size 32336, episode return 178.0\n",
      "Episode 200, epsilon   0.01, batch size 32484, episode return 148.0\n",
      "160\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABLhklEQVR4nO29eZhcV3Wv/e6aq+dRUndrni3LWJLlCQ/YZrANBJuEBAwXEyAxSUhCHhIIhHy58CXkSwjTzQ2XXDsMhjCG0RDj2QyeJEuyJUuWZLXmbvU8d1fXvL8/zj6nTnVX9aSeqnq9z9NPV506VbXrDL+z9m+tvY/SWiMIgiAUF56FboAgCIIw+4i4C4IgFCEi7oIgCEWIiLsgCEIRIuIuCIJQhIi4C4IgFCG+qa6olPIC+4BWrfWblVLrgO8CtcB+4N1a67hSKgh8A7gC6AHerrU+M9Fn19XV6bVr187sFwiCICxR9u/f3621rs/12pTFHfgQcBSoMM//GfiC1vq7Sql/B94PfNn879Nab1RKvcOs9/aJPnjt2rXs27dvGk0RBEEQlFJn8702JVtGKbUSeBPwH+a5Am4BfmBWuR+40zy+wzzHvP5as74gCIIwT0zVc/8i8FEgbZ7XAv1a66R53gI0mcdNwHkA8/qAWT8LpdQ9Sql9Sql9XV1dM2u9IAiCkJNJxV0p9WagU2u9fza/WGt9r9Z6t9Z6d319TstIEARBmCFT8dyvA96ilHojEMLy3P8XUKWU8pnofCXQatZvBVYBLUopH1CJlVgVBEEQ5olJI3et9ce11iu11muBdwBPaK3fBTwJvM2s9h7gp+bxA+Y55vUntMxOJgiCMK9cTJ37XwMfVko1Y3nqXzHLvwLUmuUfBj52cU0UBEEQpst0SiHRWv8S+KV5fAq4Ksc6UeB3Z6FtgiAIwgyREaqC4OKJYx20DYwudDME4aIRcRcEF3/8nwf41nPnFroZgnDRiLgLgot4Kk08lZ58RUFY5Ii4C4JBa43WkEpLcZdQ+Ii4C4LBFnURd6EYEHEXBENKi7gLxYOIuyAYbFFPirgLRYCIuyAYbHFPi7gLRYCIuyAY0qZIJiWzZQhFgIi7i0eOtHPjZ54kIaVwSxLx3IViQsTdxenuEc71RojEUwvdFGEBkGoZoZgQcXdhn9NJidyXJCLuQjEh4u4iLd3yJY3YMkIxIeLuIi2lcEsae/9LQlUoBkTcXWRsGTm5lyJiywjFhIi7C9uWSabFc1+KiC0jFBMi7i60FltmKZOWyF0oIkTcXYgts7RJirgLRcSk4q6UCiml9iqlDiqljiilPmWWf10pdVop9aL522GWK6XUvyqlmpVSh5RSu+b4N8waUi2ztElJQlUoIqZyD9UYcIvWelgp5QeeUkr9wrz2Ea31D8asfzuwyfxdDXzZ/F/02JqeEM99SSIXd6GYmDRy1xbD5qnf/E109N8BfMO87zmgSinVcPFNnXu0nNxLGqmWEYqJKXnuSimvUupFoBN4VGu9x7z0aWO9fEEpFTTLmoDzrre3mGVjP/MepdQ+pdS+rq6umf+CWcSplhHPfUkikbtQTExJ3LXWKa31DmAlcJVSajvwcWArcCVQA/z1dL5Ya32v1nq31np3fX399Fo9R9izDkgp5NLEvqiLuAvFwLSqZbTW/cCTwG1a6zZjvcSArwFXmdVagVWut600yxY9aSmFXNLYidS0JFSFImAq1TL1Sqkq8zgMvB44ZvvoSikF3AkcNm95ALjbVM1cAwxordvmoO2zjhZbZkmTdnpusv+Fwmcq1TINwP1KKS/WxeD7WuufK6WeUErVAwp4Efgjs/6DwBuBZiACvHfWWz1H2Od0SmyZJYkTuYu4C0XApOKutT4E7Myx/JY862vggxfftPlHbJmljUwcJxQTMkLVhYxQXdpIKaRQTIi4u5C5ZZY29n6XhKpQDIi4u8jUOYvnvhQRW04oJkTcXTjTD4gtsySx7RhJqArFgIi7C5nydWkjkbtQTIi4u7BP7oTcIHtJIpG7UEyIuLvI1LnLyb0UScqUv0IRIeLuQrrlSxupcxeKCRF3F1rq3Jc0MkJVKCZE3F1IKeTSRiJ3oZgQcXchtszSxp1rkehdKHRE3F040w/Iib0kcbtxklQVCh0Rdxcy5e/Sxm3HScWUUOiIuLtIOZ6reO5LEffwBhF3odARcXchtszSxj1hmBwDQqEj4u7CqZYRW2ZJIglVoZgQcXdhB24JsWWWJG5xl4SqUOhM5R6qIaXUXqXUQaXUEaXUp8zydUqpPUqpZqXU95RSAbM8aJ43m9fXzvFvmDUyde5yYi9F3LaMHANCoTOVyD0G3KK1vhzYAdxmbnz9z8AXtNYbgT7g/Wb99wN9ZvkXzHoFQVqqZZY0bp9dxF0odCYVd20xbJ76zZ8GbgF+YJbfD9xpHt9hnmNef61SSs1Wg+eSTEJVbJmlSFrEXSgipuS5K6W8SqkXgU7gUeAk0K+1TppVWoAm87gJOA9gXh8AanN85j1KqX1KqX1dXV0X9SNmCy22zJImJeIuFBFTEnetdUprvQNYCVwFbL3YL9Za36u13q213l1fX3+xHzcryJ2YljbuJKokVIVCZ1rVMlrrfuBJ4FqgSinlMy+tBFrN41ZgFYB5vRLomY3GzjV2tCZR29JEbBmhmJhKtUy9UqrKPA4DrweOYon828xq7wF+ah4/YJ5jXn9C68IIg5zpB8RzX5JIQlUoJnyTr0IDcL9Syot1Mfi+1vrnSqmXge8qpf4BeAH4iln/K8A3lVLNQC/wjjlo95zgJFTFllmSSCmkUExMKu5a60PAzhzLT2H572OXR4HfnZXWzTMy5e/SRhKqQjEhI1RdSCnk0iZr4rDCcBIFIS8i7i5kyt+ljdgyQjEh4u5Cph9Y2ogtIxQTIu4uZMrfpY3MCikUEyLuLtJSCrmkcYu7XOCFQkfE3YUdrRXyfO6D0QRHLgwsdDMKEhmhKhQTIu4unOkHCjhq++azZ3nbl5+lQMaNLSqyRqgW8AVeEEDEPYtiSKgOjiYYTaTEVpgBKa3xe5XzWBAKGRF3F86dmFKF67nHklbbC/k3LBSptMbvtU4JSagKhY6Iu4tiiNxjyRQAiWTh/oaFIpXWBHzWKSE9H6HQEXF3UQzTD8QSVsQeS6UWuCWFR1bkLraMUOCIuLvITBxWuJZGLGXbMiJO0yWtNQEj7jJKWSh0RNxd2BUmaV24nqsduSeShXuBWihSaU3Q2DKSUBUKHRF3F249L9ST2/bc4wXc+1goUhpJqApFg4i7i6wRigXaLberZeISuU+bVDotCVWhaBBxd+FOohXqFARxKYWcMak0Tp27JFSFQkfE3YXW4PVYJ3ehR+6SUJ0+aVe1TKHuf0Gwmco9VFcppZ5USr2slDqilPqQWf5JpVSrUupF8/dG13s+rpRqVkodV0rdOpc/YDbJqpYo0G6547mLLTNtUjpT5y6Ru1DoTOUeqkngL7XWB5RS5cB+pdSj5rUvaK0/615ZKbUN676plwKNwGNKqc1a60VfeG2L+2iicAcyOdUyYstMm7S7WqZA978g2EwauWut27TWB8zjIeAo0DTBW+4Avqu1jmmtTwPN5LjX6mIkrXEit0IVR7tKRqplpk9SRqgKRcS0PHel1Fqsm2XvMYv+VCl1SCn1VaVUtVnWBJx3va2FiS8GiwbtsmUKNXKLJcSWmSkyt4xQTExZ3JVSZcAPgb/QWg8CXwY2ADuANuBz0/lipdQ9Sql9Sql9XV1d03nrnJHW4Hcit8IUR5k4bOaktSuhKuIuFDhTEnellB9L2L+ltf4RgNa6Q2ud0lqngfvIWC+twCrX21eaZVlore/VWu/WWu+ur6+/mN8waxR6QlVrLeJ+EViRu0IpSagKhc9UqmUU8BXgqNb6867lDa7V3gocNo8fAN6hlAoqpdYBm4C9s9fkuUFrjXZ57oVYCucuf4wXYPsXmrTWeJTCq1TB2nKCYDOVapnrgHcDLymlXjTL/ga4Sym1A9DAGeADAFrrI0qp7wMvY1XafLAwKmWs/4XcLbfLIEE895mQSmu8HoXXI+IuFD6TirvW+ilA5XjpwQne82ng0xfRrnnH7oYHnFK4whPHmEvQxZaZPsm0idxF3IUiQEaoGhxxL+ARiu5oXWaFnD5pV+ReiD03QXAj4m6w82eFXOfsjtylzn36pHRG3CWhKhQ6Iu4G+2S2J44qTHF3ee4i7tMmnbbmFpKEqlAMiLgbxiVUC1Ac7akHQO6hOhNSWuMVz10oEkTcDWMTqoUYubuj9bjcQ3VaaK1JpTUeqZYRigQRd4M2uljIE0dJ5D5z7N0tkbtQLIi4G1JjqmUKsZTQ7bkXYvsXElvMvR7Ldy/U2ywKgo2IuyGTUC3gyF2qZWaMvf+9Ho8kVIWiQMTd4Ih7IXvuRtxDfo+MUJ0m4yL3Atz/guBGxN3g1LkX8CAm25YpC/rElpkmtg0jI1Snx/6zfXzqZ0cWuhlCDkTcDcU0/YAl7iJO0yGVsiN3Effp8MiRdr729BmiiaVdnfXAwQv8+IWWhW5GFiLuhvSYyL0QxdGulikL+cSWmSYpPUbcZymhGk+m0QWcnE2lNZ99+Dg9w7Gcrw9GEwD0ReLz2axFx3/85hRfe/rMQjcjCxF3g33nHXuEaiFGbnYStSzok4TqNLH3v0cpPLOUUB2OJbni7x/lsaOdF/1ZC8XJrmH+7clmnjiW+zcMjiYB6BtJzGezFh3tA1GGY8mFbkYWU5nyd0mQmVvGCxRmQtW+xV5pwMdQNLrArSks7Ejd51H4ZsmW6RmOMRRLcqZ75KI/a6EYjVvHVD7hsiP3/tGlG7knUmm6hmOoXHPnLiASuRvGzS0zD5Hvu/7jOe5/5sysfV4smSbo8xDweSShOk1sMfd4FJ5ZEveRmCWMI/HFFdFNh4gt7tE84j5qxD2ydCP3rqEYWuffRjbf2XuOt//fZ+epVSLuDql5nn5Aa83e070cbOl3lsWTaZ441jHjz7TF3e+VUsjp4pRCqtmL3CNG1G2BLETsROlQ3sjdWr6Uxb190Oolj8RTE95Y/XDrAPvP9s1bDkbE3aBdpXCzdXJPRCSeIpHSDLmu9k8c6+B9X9/HsfbBGX1mLJkm4POayL3wbKWFJFPnnkmofvj7L/LD/TOvgBgxoj6yyLzY6TBqi/skkftSTqi2D2Qs0Il6aaPxFMm0zhpsOJeIuBtsLbfrnBNzXAo5YE6KoWgm4ukz0U9r3+i0PuvhI+184scvEUumMpG7y5b55ANHeOhw2yy0unixbTmPJ5NQ/fmhNn7y4rh7u0+ZiBH10QKO3CMTeO5aa8dzt4/npUiWuMfy7+vIPF/sp3KD7FVKqSeVUi8rpY4opT5kltcopR5VSp0w/6vNcqWU+lelVLNS6pBSatdc/4jZwDm5lTUFQWqOI1+7G+uOiOyd3jYwvWToL15q49t7zzESSxL0ewh4VZYt873nz/PIy9Oze6KJFH/+nRc43xuZ1vsKFftaaCdUh2NJ4sk0L18YnHE32oncC9hztyP34eh48Y4m0k4PsW9k6UbuHYOZ83U4lv8iFzHbcr5suqlE7kngL7XW24BrgA8qpbYBHwMe11pvAh43zwFuBzaZv3uAL896q+cAO1BXan5us2ZHOoOuk8aOjtwHy1S4MBBFazjXO0rAm51QjSfTjCZS0/ZEj7cP8cDBCzx3qmda7ytUUu5SSI+ie8iq6+4ZiTue6nQpCs89nt+WcR+7/Us4cncHY8MTRO7RSSqPZptJxV1r3aa1PmAeDwFHgSbgDuB+s9r9wJ3m8R3AN7TFc0CVUqphths+27gj9/KQb867mQOmdMx90tjZ9ulG7hf6LRvnbM8IQb8Xvzcj7kMzHGTSZcStkIUpH+m05nOPHKe1P2N/pV2DmHwe5SQKAY60ziwHYp/EhbwNncg9hyANus6R/qXsuQ9G8XmsKruJKmYiCeu1RWPLuFFKrQV2AnuA5Vpr28htB5abx03AedfbWsyysZ91j1Jqn1JqX1dX13TbPetol+feWBnOOvHnArctY3f77e77dCL3VFo7nl8knvHcEyltPNGZVTN0mRGJk0UZ395zjubOoWl99kJzYWCU//1EMw8fbneWJV0Th3k82QXLhy8MzOh7IrHCT6hGJojc7QCoNOBd2tUyA1HW1pUCE58vE+Uv5oIpi7tSqgz4IfAXWuusUEZb6jQtH0Nrfa/WerfWend9ff103jonZBJq0FgVcqLhXMxGKZN9YqTS2hUdWf+nE7l3D8eyLCS7zh2sEaszrWawI/eJhCmeTPM3P36Jb+85n3ed+eaVjiG2/O0vONuTf+CQLVRuwXLbMl7XaJSA18ORCzOL3EeKwZaZKHI3vcLVtaVOMUAx0TkU5fv7Jj62tda0D0bZWF8GTHy+2In1xeS5o5TyYwn7t7TWPzKLO2y7xfy3xye3Aqtcb19pli1qbHFXStFYFaZjMJqzHPLJY53s/PtHJxQPm/O9EX71Su5eidujtEXGPjA6piHuY3sYQZ8na34cdzXDdMo7p2LL9IzEsv4vBo63DxFLpjk1wahQW6jcya+xtozNFWuqOdJ6cZF7pJATqq5oc2xQY089sKamhP5IvKDn0MnFjw608tEfHJowWdwfSRBPptm4zBL3iaLyiSyuuWAq1TIK+ApwVGv9eddLDwDvMY/fA/zUtfxuUzVzDTDgsm8WLWlXnXtDVZhEStM9ZrKkzsEof/lfB+mPJHjxfP+kn/kfvznFPd/Yl3Ngg7sba/vitl83FEtO+QCwexj27QGDPq8zyjaRTDs9BK2zPdLJ6J6CLWNfAHoXUaWE3ZaJfqu9vXNF7l4zQtXm+k11XBiIzshTLobI3a7wcPcwbTKRewnJtHaqg4oFu7ebr8YfMr3sqYj7oiuFBK4D3g3copR60fy9Efgn4PVKqRPA68xzgAeBU0AzcB/wJ7Pf7NnHfQ/NpqoQMD4q/tTPXiYST6IUnOmevESwZyROLJnmwsB4i8ctPrYv7j4w2qcYvdvifvmqKsASeX+WLZP5zOlYM5nIfXJx7x5ehOI+wQmZy5ZJjxmhCtYEbKtrSoDMb50OEVc3fKKRi4sZd43+2GShfQyvMtuo2MohB+y82ATljXZ+bFVNCX6vyivuqbR2ypMXjbhrrZ/SWiut9au01jvM34Na6x6t9Wu11pu01q/TWvea9bXW+oNa6w1a68u01vvm/mdcPJlZAaGhMgxAW3+2wB5q7efWS1fQUBHizBRsGTtqznUh6B+N4zUi4tgy8SQrKqwLy1STqhf6o5QFfWxdUQ5Y0yfYtwqMJ9NZ5WqT+aK9I3Heed9znO+NuBKq+aMxO7rPNx3sQjCVyN0Wfve2cU/5a0fuVSV+KsJ+YPwgHa01+8/2TmhFuE/isVFvoeCep33sFASD0SQhv4dl5UGg+AYy2b3riSpg7Iv+svIgZUFfXuF27/+JzqnZREaoGuzAyvbcgaykqtaarqEYyytCrK0r5bTL0/32nnN8/tFXxn2mfXCcznEhGBhN0FBpCbltE4zEkk73zp1UHYwm+MA392UJ/s8PXeAffv4yF/pHaawKORekoM/jWDQJV0LVas/EkdWL5/t45mQPv3ylKxO5T9GWWSx+ayZyn54tk3RNHGYnVKtLAlTmEffHj3byO19+lu8+nz/h5rZjpjqQqX0gOmHb5xu3KI21JwZHE1SE/FSXBIDim4KgP0e58lg6h6xzsr48SGnQl/dC4O4Bz1cORsTdoF117hUhH2VBX5YtMxxLEk2kqS8Lsrau1Inc02nNFx97hX974sQ4G8c+OHJN+dofSbCq2urO2tbJUDTJhnqrpOqZ5m4+9N0XGIgkOHR+gIePdPDsycyAogdfauM/njrNs6d6aKgM02isJLvOHYwtM43I3Z724MDZvimVbdninkxrBkeT9I3EF/yOPJnIPftkcovzcA4bzG3LeF2Ruy3uYwX31yesRPlnHz6eN2LNitxz+NHJVNoRB5u7v7qHD33nhYl+4rwSiaecbTDOlokmqAz7qSqxXi+2ckgncp/gHOgcilER8hHyeykL+vKum2VvLRZbZqngzC3jUSilaKgM0ebyym0hqy8Psq62lP5Igv5InBfO99M5FCOt4Tt7zmV9phO55xD3gUiCVTVWtD0UTZBMpYkl09SWBakq8fOjF1r56YsXONjS71SjuKN5++YIQ9EkjVVhmqoykbst7omkJbq1pQHTnokjqxZzcfqNES6vR02YDOxy2THdIzF+69+e4ouPnZjwO/KRSKVn5cKQK3L/258c5r1f2+s8z3juLltmzMRhMCZyHyNcTzV3s76ulN5InC892ZyzLSPxpCN8ueYc+eGBFl7zmV86n51Oa850R3jyeNeUqrHmg2giRb2xXezqor2ne/nSk80MjiapyBL3mUXu8eTs7PvZxpn/aZIAZ5mxUicS96xenIj7/OIeoQrQWBXmgstzt8W9zkTuYIn2w0fa8XsVV6+r4bvPn3OSJslU2hGRsZF7MpVmKJakoTKMR1liY5/8pUEfq6pLCPmtXdM9HHMEy32x6YvEnZsDNFaGaDDiHvB6nGoZO3Jvqg7j9ahJu8125G4nSJuqwhMeiF1DMUcIT3YO09I3yisdMxvQ9NmHj/N7szDXdW9kvOd+tG2Iw62Dzhz9uWyZXKWQ1SV+KkLW/WwGXD2B9oEop7pGuOuq1dx26Qp+/EJrTlsqEktRV2YJY66u+KmuEUYTKWfa595I3Jnw7dtjAoXporWelZlNR+Mpx1O3t9cXH3uFf3n4OEfbBqkI+agK28HDzCL3v/vpYd77tecvuq25ePJYJ49OY14lrTOJz6l47p1DMWf7lE7Rc59ocrHZRMTd4K5zh/EDmWzBqy8Psq7OslNOd4/wi8NtvHpDHX900wa6h+NOXbt91S8P+jjXG8m6+Yed0Ksu8VMW9DEUTTBsTv6yoJf/9Y4d/OSD1wHQMxx3iXvmYtMfSXDrthVct7GW6zfVsaIixOu3LefKdTXOICbbc68M+6kK+ye3ZcbYSmtqSya1ZdaZC93+c33WZ0xzRkub090jvNIxdFHevdbaqdgYdEpANed7I8RTac6ZSdBskYrEU85+sXdPdkI1gM/roTTgzbJenm7uBuDVG2t5zeZ6uoZiNHcOj2vLSDxJvRH3XGWCdsBwyIi7ncCvKvHzvX3nLyqa/fbec1z3T09c9E1bIvFklrj3jsTZc7oXsKrBKsJ+Aj4P5UEfPTOsljlwro/mruHJV5wBn33kOJ956NiU1//HB49y3T8/wWg85apLz3/edA5FnZ5NWciXN8q3bZmgzzNvE8mJuBvc0w8ANFaG6RmJO3Ord7kSJ6tqSvAouP/Zs5zvHeX27SvYvaYasO45CZlBSq9aVUkyrbOE0xaKyhI/5SE/Q9GkEx2UBn2sry9jy/JyAl4P3cMx56QZG7mvri3hW39wDTtXV+P1KO67ezfXrK91BjHFTZ17RcjqOufqNh9vH+LyTz3Cqa5hWvtG2by8zHltXV0psWQ6712puoZiTpXO/jNG3PtHZyTQg9EE0UR62jXh7/3aXj73yHHrM0aTTmLUvoD2RRLOBcoW4Kz5fMxrSTNznHuEarWxGyrD/nHiXlMa4JIVFVy3sQ6wbBo3sWSatIZlFdaJP5rjhLZtrYMt1iApe/++86rV9EcSM+4FARxtG6R9MDqlW/w9d6qH/Wf7cr4WTaSd3sdwLMljL3eQSmvHBqwIWduovjyYZdNNlVRac6YnQu9IfNbLRbXWnO4e4WxPZEq9mMePdnDfb06Pu1jnS6jaRRb2xa8skD9yt4/r+vIgI7EkP9zfwms/98s5LZEVcTek0tm2zI7VVXgU3PbF3/B/ftlM13AMn0dRFfYT9Hlpqg5z8Hw/V6yp5o4dTZSH/FSX+J3o0O7S7TD1527f3RbZqnCA8pCPwWhm0FJZ0LIBlFLUlQXoHo7Ta3oNdu37aDxFLJl2vM6xOJ57Ks1gNElF2Ed1SSDnTYz3nullYDTB40c76RyKcfOWZShlRbArq60T2I46z/dGHD8+Ek8yEk+xZbkl7ofMKM7hWDIrmTlV7PeMHTg2GS+e73eE1bZkSgNeJ3J3T1lsR4fu6Mo+cd22jOO5m1xFhUvcByIJHnm5g5s21+PxKFbVlLC6poSnm7Nnz7RPcidyz9EVHxe5m/27c7UVKIzdFum05oGDF6Z0l63uIWtbHG2f+AIxEEnwB/fv4657n+OXx7Nvgp1MpYmn0pSH/IT8HoZjSR460k5TVZgPv34zABVh63itKw/OaCxAa98o8WSaVFrPepVQ+2CUSDxFPJWmpW/icSnRRIqP/uAQpQHrHsovt2VGJeezZYZMkcWycuO5h3x5LRfblrPEPcW+s72c7BqZ0wojEXeDe4QqwA2b6nnub17L9qYKHj7SQddQjLqyoNNlv2ptLbtWV/G1915J2BwQq2tKHDGxZ33cuco6Uf/4Pw/w2//nabTWTlRfEfZTEfIzFE04YmCLO0BtWTDLc+8ejhNLppwDwi5BG8tYW8aK3AM5D6STJkL575esQcQblpWxrraUmtIA5SYqi8STjMSSvOere/mjb+5Ha+2IR0NVmMqwP0twWvqnPwe8fWJPZ0BUKm1ty+aOYbTW9JrE85raUgajCbTWzsVWKXfknqDE7DNb3B1bJqtaxtq+lWG/c7H4+jNnGI4l+cMb1zvtuG5jLXtO9WT1cNyRmvU8R+Q+FMPvVXQMxugYjNI2ECXg9TgXzLHb4heH2/nz77zAr/NMaeHGvjAcbZt4Xpz7n7V+z8rqMB/45v6su4BFzT4tCXgpC/ppG4jy1Ilubtu+gtu2r6CpKszWFRXO77SnSX6pZWBcFVA+TnZnIuTZHgx3qmsk5+Nc7D3dS89InD+5eSMAL7vmE8pntXQOmhr3ioznPhxL5ozGbYutrizIcCxJi7EvO2dwQZwqIu6G9BhbBmBZeYgr19bwSvsQ7YMx50QF+Ozvvoof/vGrnW4pWKPUzo+J3DcuK+Nv33QJu9dWc+BcP639o45QWINkfCahmrFlbOrKAvSMxLLmbukYiLnEfeLIfSiaJJZMUxG2ehW5El4nzIyO9nQKK6vCXLuhlksaKhwBHIkl+dTPjnCqe4SReIqReIqu4YxNVVsWcH4PTN137xyMOtvL3ibTidwHRxNobZ18nUMxek3PZG1dCYmUJprI+Ow7VlU5FzK7wsh6nKlUAfB63dUyGVtm0FyAv/bMaV53yTIuaahw2nHdxjqGYklu+MyT/O1PXgIydk8moZod0SVSaXojca5eVwvAwfP9tA2MsrwySF15IOe2+PEL1i3/OqYgnLZFcmwCcR+JJfnq09bv+a8/upaSgJdPPfCyY6vZF6RQwEtFyMfjRzuIp9Lcvn0FpUEfT/31zfzW5Y2A1UOxv/Pur+7hMw8dn7SNkC26YwfD9UfiOW85+dypHt79lT2T5iROuXz8k5N4+k8e7yTo8/C2K1YC8LLZbqUBb97I3alxN/u43Jy7kRztsvd/XVmQSDzp2LQi7vOAU+c+Zotc0lDBaCLFi+f6ssRdKeUkX21W1ZTQ0jdqRZSRjID/wQ3r+fPXbgLgRMewk/SrDBvPPZZwooNxkfuQlVC1E5dtA6Ouz84TuRtxt736ipCPqhJ/zsi9uXPYETOApuowf3/Hdr7++1c6bTndHeH7+1pYU5sZip+pHgpQV2ptl+s2WP7zRDNquvmfDxzhT751gHRaO7+/ZxrRW6/r9zR3DjuR+9paa1sNRhO09EWoKwvwqqZKTnaNkE5rhmNucTeRux5f5273jGxb5oljnfRHEtxz44asdrx263LuvnYNKypDfGvPOdoHoo4w1pQFUCpjbf36lS4+/P0X6RmOozXctKUer0dxsKWftoEoDZVhSgI+SgLerG3ROxLnl8etiH0q9ocdRR+bwJZ55OV2+iMJ/ug1G6gtC/LhN2zh2VM9PHzEmgo5Grci97DfS1nIRyRulUXuMraR+/ivLw8yFE3SORilL5LgpZapTbbmFuCxCdnPPHyct/zb0+NGa//oQAu/OdHtJLbzcbJrhJKAl6oS/4QTyQH88ngX126odUaaHm2zttvK6pK80w84o1NdkTvktnHcPblESjtBzUysrKki4m7IFbkDXGK6nYPRTOVDPlbXWBMotQ2M0j+aQCkca2PzMqurfbxjiFc6hykP+agpMZ77aL7I3bJl+kcTXNpotaNtIDqpLeP3Wb/BjoSsWuQAsWQ6azDFYDRBx6Dls4NlXTRUhq37iHqU05bjJnp67VZryn63uLsj952rqwj6PDnnwu8civJn33khKxo93T1C28AoQ7Gkk9CezlQG/WPE3RYHu1R1cDTBud4Iq2pK2LisjOFYktM9IyYhaEYHxzJTL4N1ca8rC1Ia8Dq/y06o2rXnlzVVZrUjHPDy/96xnc//3g60hgcOtjrea3nQR4nf64z0/bcnmvnRgVaOmDniV9WUcFlTJU8399A+EHVGLdv73ubnhy6QTGu8HpWzd9M5FHUClFHTu6ousayUfPXn+870URb0OR7/XVeuYtOyMv79V6eszzERqGXLWMfCG7YtHzffPWSi1wPn+q390TU8pWqfU10jTnJ27L5/7mQP8WSa+359Kmv5XlOt85BrPn43fSNxBqMJTnWPsL6+lPV1pVkXkbGc7h7hdPcIt2xd5oxxsXteK6vDeSP3zDmQ8dwh9yCl0XgKj4Ia0xu0b084VftqJoi4G8bWudtsWl7mLHNH7rmwJ5k63zvKQCRORcjvRIGVJX6WVwR5pWOIA2f72LGqCo9HUR6yfLpMtYzX+by6sgDJtEZruLTREhRL3C1Bqi7Nbcs4kbuJ/CrCfmpMctBt8dg2xZ07G/F7FcvKg45fD1AasA7Wk6brfPkqqw3dwzE6BmPmYA04Iri+vpSmqsyNTrTWjrD8/GAbPzt4gW8+e9b5/Na+UXpH4lkDhKZjy/S6EsQnOofoG4kT8ntYbgaVDEaNuFeXsMFM63DAVIXY0zVkPPdM5H7njkZ+9dGbKTG/vzLsJxJPcap7hPryoJNjGcu6ulJ2rKriRwdanci9NOijJOhjJJ7ifG+EvWcsYbITsPXlQW7esoyDLf1c6B912lVbFsiK3H/64gW2rihnXV2pk++w+cH+Fq769OP8YH9L1jZ8tankcUfv7nLRA+f62bGqyjlGfV4Pt2xdxssXBokn085vCPsz4n779tw3VbPPjRfO9znb81j7EF996jSPTVBnfqp7mN1r7QRy5nd1DkU51T1CacDLt/acc/JOnYNRzvRECPg8PHq0I2ep5/vuf5533beHk53DrK8rY3192YSe+5PHrETyTZutIMfu1fk8iuUuoR9L51CMgM/jjIUoM+euvb57GuTRRIqSgC8reLN+j0Tuc87YOnebkN/rWCJTF/cI/aOJcdUsm5eX88K5fl7pGHK6tuUhP6m0pms4RsDrIehzi3vm+1bVhKkI+axewUim2iYX9qyQtgdaEfLnnJDMTjBua6hg56pq53fa2Bcaez07Yu0aitFqhMjn9VBrbJm1taU0VYcdz/3p5h52/8NjHG0b5JmTVhf6O3vPkUhZJZpDsSRpjeOLA3SP6Zq7B5WMxe7B1JcHnci9tjTonGw9w3Eu9EdZXVPCZpOkPGDq8cfZMq4Rqj6vJ2vb26NUj7QOsspUEOXjrTubONY+5JQWlhqLZTSe5KcvZm5rYFsK9WVBbt5aj9bWNA65IvfOwSj7z/bxpssaTAVVRhAefbmDj/7gIJApx7T3+42bLHF3JwcffKmdq//xcQ63DnC8fZBdq6uy2v+qlVXEU2mOtQ86kXvI76W+PEhNaYCr19fk/N2OuJvIHSwL6tMPHuUzD+euMx+OJekYjLF5eTnVJf6sqaP3mdLaT77lUqLJFO/9+vOc6hp2Lo5/cP06+iMJJ4q3GYklOXi+n5daB2jtH7Ui9/pSOodiWSOS3fz3S21sWV7OamM72sdGVYmf8pAvbymkXQZpa0ZZMDNNw/neCFd++jEeP2pdOCLxFCG/N0vcPYoZlY9OlSUv7md7RvjB/pZxde5u7OTZZOLeUBnC61Gc643QF0lQFR4v7qe7R0hr2GXq4m3hONMTyYraASciBqgtDdJQGXYi97KgLyvKdmNH7nYkVBn20WBsCLvcTmtNc9cwAa+H1TUl/OtdO/nC23dkfY59IDZ3DlMS8LK2thSvR9E1FKOlL+KUSt6wqY43bFvO6pqSrMj9eMcQybTme8+fZ8+pXtbWltA5FOPRlzuykq72xGoelfGKbe5/5gzX//MTOeuU7Qj0yrXVNHeO0DsSp7o0Mx/M8fYhUmnN6poS6sqC1JcHHTGoLQsQ8HrGlULmshzszzvROeRcwPPx5lc14FHWjR4ASoJeSgI+hmMpfvxCK1etq6GuLMBxU8NeVxZke2MldWZfZ8Q94Ow/2wO/bfuKcXbNd/aeo6k6zE1b6p0Ll70NtzVUsnFZGd987qxzgXz+TC/xVJqP/egQaQ07zXFo86qV1gX8YMuAY6uUBLz85Ru28KM/frWTrB+LfW4caumnLOijIuTjvl+fIpXWvNIxnDOhaQcNG+qt6ix3r3Lv6V7Cfi937mziS+/cxZnuEd7yb0/zn8+dpSTg5Y9v2kDI7+Gxo9m9goMt/aR1Jrm/vr6M9XVWry3XNCBne0bYf7aPO3dm7gTaaPZBZdhPedBHLJkeF2Cc64lwtG3QqXEHnPmdTnYN83RzN4mUdi5Go/EkJYFscd+8vJwuidznjv/a18JHfnBwXJ27G1vc6ybx3H1eD41VIc73RRiIxMclPO0SN8jUv9sR/HMne8Z12dzfV1sWoKEqREvfKP2ReN4ad8hUy7SbQTEVIT8NFWGzLMr+s71s+duH+PZz51hXV4rP62FFZWZmSRu7PaOJFCsqQ3g8Vu1911CM872jrDQTn+1eW8O9d+/G5/XQVBWme9iaQKzNiPy39pxlKJbkw2/YQlNVmO89fz7Ll7cH2qysLhmXVPv1iW46zcVkLH2RBH6v4vKVVXQPx9hzqpe6sqAzTe8zZqI125LZuqLcsZjKgz4TlWV77r4cB4Bdy53WTCrutWVBrl5X6/yO0oCP0oCXgy39nOwa4Y4djU4vojzoIxzw4vEoXmMsAceWKQ3SOxIjndY8dKSd9fWlbFxWZpUcuuyLY22DXLG6mus21HG+d5SuoZjzel15gE+86RJOd49w/zNnrPVN/uSwuen3rlXZ4r6yOkx1iZ9D5/sZtROqAS81pQEnl5GLmlIrcRxNpFlZHebSxkqGTIkl5PbHnztl7Z9dq6tN2W/md+053cuuNVX4vR7eeFkDv/jQDdSWBXjuVC9XrKmmPORn8/JyTnRkXzTsnsOX33UF2xoq2L2m2hmYd6xtiHRa883nzjqltz954QJKwR07Gp3PyETuAceOclszT53o5qbPPsmx9iFebYoIrG1XwqqaME81dztBxGEz/sOyZbyOdVMW9LFhWZl47nNJNJFCaxzvLlfk/prN9ayvK2XTsrJxr41ldU0J5/LZMmY056ZlZU40uHl5GY2VIeKpdFalDGRH7jWlAbY1VHCiY4i2gWjeZCpY1kLA66EvkqCpKkx1aYCKsGUPXOiPsu9MH/FUmvqKIK/btizv55T4Mz2JRiM6dWVBWvtH6RiKOieum5VmMrSWvlHajAVkJ4+u31jHa0yE6RZrW9zX1ZVmRaVaa2eATy7PtG8kTnVJgOs21tFQGeLWS5fzkVu3UG5smT2neygNeJ1o1F2+WB7K7nKnxoxzcFPp6oGtnETcwYqwwUpQh/weSoI+uoZiKAVv2LbCEXd3T/BtV6xk47Iy1plZQevKAqS11at57lQvt29fYQa2WXXSo/EU/ZE4FwaiXNJQwa41VYBlO9mJvtpSy8+/eUs9//r4CUZiSY61DzlBxob6UirHHKNKKV61soqXWgeyPPfJ8Hs91JhjcmV1CdubrG39+69ey+Wrqpzeh5unm7vZvLyMZRUhq+x3ODOo61j7IFetrXXWbawK860/uJpXrazkd3ZZ5Yq5EqUHzvaxob6UazfU8uCHbqCxKsza2lLKgz4OtvSz/1wf/89PDvONZ86gtebHL7RwzbpaR9Dt7wKrFNYuiHAnVe/9zSnqy4P85qM381e3bsn6/us31vHcqR7nwnXkwiBa63G2TGNViGUzHPg1VZa8uNsTNcVMtyvHuc32pkqe+KubnBGLE7GtoYLDrQO0DUTH2TL2xcGO1q3vU9y01RLYseJeU2JFQ0pZlTG7VleTTGv2n+2bMHIH+NK7dvHV39/Nk391E36vB6UUKypDtA+OcqZnhJrSAE/85U185NateT/D41FOrfsK01WtLw9yqKUfrckp7qtrLHE61ztCW/8ou9dUUxHysa2hgprSAJevrGQomswa0WnbMuvrrdk27QvthYGoE83l6tb3RSxx395UybMffy1ffMdOLm2sJOjzEvJ7SGu4en2t05O5pCHTcyoP+ay5QOzIPZXx3MfiFvfJIneAWy+1xL004EMp5Vwkr1xbQ3150BH3Ope4X7uhlsc+/BrnGKg1vbafvNBKKq15/TbrM+2qlO7hmJMo3dpQwaWNlfi9igPn+ugejlFp5nwB+MMb1jMUS/KjF1rpjyR41zWruWpdjdPOsVy+spJXOoYcDzxfAnks9sVqZXWYGzfXs6w8yFt2NHL79hUcahnI6q3FkimeP9PrRL61pUF6RuIcbx/i3V/ZS1NVmLuuWpX1+SurS3jgT693LJT19WVccJWdaq05cK4v6/wC6zi+bGUlh1oGMpU2R9rZe7qXMz0RfntXU9b6tr1SGQ44FTB2VdWZ7hF+/UoX77xqjXMHKjev3lDHUDTJhYEom5aVMTCaoKVvlNG4FbnbRQpNVWGWlYescSNzNEvkVO6h+lWlVKdS6rBr2SeVUq1jbrtnv/ZxpVSzUuq4UurWOWn1LGJ7afb/XJHbdPjDG9cT9HmJJ9NUjomuS4M+vvD2y/njm7LrpG8xpYhjbRmf10N1SYCqsFV1s9Mkv+Kp9ISRO8Drty3nlq3Ls3z5xkprpsvT3SOsrZ1cpNxtsn3I+rKgM2+Lbcu4sWvhz3RHaB+Isrq2hP91104+dcelgJWwA2s+dHvKY7vm107o2qJyyHWf2lx1yn2ReN6KIXtwmT33C+CMpgRL3MuDfqe77a5zH/dZ0xT3FZUhdq6ucnIoJeb/bUZMt6ywLvIT5XBsS+6/X2qjNOBluymFtQc4dQ3HnNGnl6woJ+T3cmljJS+c7ad7OOZ4+GDZZqUBL//3Vyet9Rsq+P4HruWjt+W+sL9qZRVpDc+bpOZUInf371lVU8INm+rZ+4nXsaw8xC0meHnqRGZk7YGz/UQTaWf/1JYF6I8k+OQDR/B7Fd/5w2ucqXTzsb4+Mzvr0bZB7n/mDH2RhJPPcnPZykqOtQ/y1Akr6Xy4dZDPPHycipCPN7+qMWvdFZUhlDIJVXP82z28b+05i8+jeMeYC4/NqzdkehvvvW4dYEXvEVvczec1VYcdv36uBjJNJXL/OnBbjuVfcN92D0AptQ14B3Cpec//UUpN7chYIGxRjyWt5FGuyG06LCsP8We3WEOYK8PjheetO1eO8y5fvdGa7Gts5A5QWxpworjasqAjnvlGp07EisoQ7QNRznRHJvRP3ZQ6kbslxG5BssV5bHvLgj5Od4/QMRSjsTLMzVuWceVaq8pi07IyQn4P8WSatbWlVIR8JFKa8pDPOdhta+ZgywB+r+LSxoqcdcp9kUTei5wtyNdtzJxsG+rL8HsVSllRtduWOdw6QHnQlzOhal8oAt5MmeVk/O2bLuHjt18CZEpKbbtmoxnzMNG4CVucT3WNcMXaGnym92GLfvdQjGNtQ9SUBpx9cvW6Gl4438ex9qGs/RTwebh+U50z5H3LinImYvfaajwKnmq2xDg0VXEvy0TubjaZXIG7t/Z0czdej3Kqb+x7Djx7qoe7rlqdMyoei50obe4c5t1f2csnf/YySsE162vHrXv5yioSKc2zp3q4cXM9APvP9vG7u1eN65kEfV7+8a2XcddVqzK169EkJ7uG+c/nznHr9hV5j4PasiCXNFRQHvRx585GvB7Fyxes5HTYHHM1pQG2N1Y6+6hzirfUnC7j1WQMWutfK6XWTvHz7gC+q7WOAaeVUs3AVcDFT9Q9R8RS2ZH7RQbuAPz+dWvpHYnz+kuWT2n9koCPT77l0pzR9Ib6MieqBMvSOdsTyTs6dSIaK0N0DEXRGtbVTlHczQXHrraxD0ivRznllW6UUqyuKWHf2T5Sae3YOTY+r4ftjZXsO9tHY2WYlr5Ra3KzkN+5iNlWzKGWfrauqGDz8nJnwjI3fSPxvFZZRchHXVkgK4kd8HnYUF9Ga/+oGWNgzRnz1IluHjvayUdv25Lzs0J+L0Gfh8aq8JQv/lesqeGKNdbj397VxOqaEsfLrQz7+fjtW7N6FWNxJ9OvXlczbnn3sDU0/5KGcqcU739cs4b/eOo0p7tHnEFvNjdvWcbDRzpoqgpnTZmRiypjAe4720fA55nyb3bbMm6UUrx6Qy1PN/egtUYpxZ7TPVzWVOm0pdb1e9+6M9smyYfd0/vZwQt0D8f4uzdv482XNzgTebmx8y5g5Te6hqyez7uuXp3zs++6ylpuBxW9I3E+/+grhPwe/u7N2yZs10du3Uz3UJySgI8N9aUcNpF72G/dSOeZj91CwOvhFTP1x1yVQ16M5/6nSqlDxrax+0FNgPumki1m2aLFidwnSKhOl6DPy8ffeIlTNzsV3nn1amfQiZvPv/1yvugqUbTrkmcWuYedks+pR+5G3Cuzxb2hMuREk2NZU1viVGXY/qUb25ppqg47g6sqwn5HuLqGYqTSmpdaB3jVysqcdcppM2lYvu1w97Vr+citW8aNW9i5ujpTblge4MJAlPd+fS+ra0p4n+lG56Iy7J9SNJmLnaursyYaA/jAazawfcxI17HfZ4vqVS5xt5PsHYNRjncMZVlNq2pKnKqPsZVdNxnrz513mIibjZVSMkW/HawJ24I+T07r6rqNdXQPx3ilY5hkKs1LrQOOzQiZyP3yVVWsr5+8cAGsXEBTVZjHj3WiFNy5symnsIPlcdvfcdXaGj78+s18+PWbJ/0uO6H65V+d5OW2QT7ztssn7b3dsnU5v3elZdtc1lTFgXN9ZrI661wK+a0KKbutczWQadLIPQ9fBv4e0Ob/54D3TecDlFL3APcArF6d++o5H8y25z7b2AeEzVVmoqkVleMtkclocAnt2AFL+bB9Y7tEL1/X283q2hLnIrKiYvx69kjXpiqXuId8NFaFqC0N8LODFwj4rBr0GzfXO591unvEuTAMRZOk0jqvLXNnnujvE2+6xEnA/fktm1hZXcITRzv4wxvWT2g/3H3tmilfEGcDj0dRWxqgfzSRFXUGfV4qw34eebmDaCLNtobsCP1PbtrIT15oHbd/VlSGuOfG9Y49Nhk3bannXx4+PmW/HeB3d6/kxs11jiC6sXspTzd3k9bWpG6Xm30JmQqVt+2aXiy4vr6U1v5Rdq6uco6lXCiluGJNNc1dw6yoDLGi0rq5zWTYlVenu0e4YVPdlN7j5s6djfzwgDVyeKz9UxX24/OoOfPcZyTuWmtn5IBS6j7g5+ZpK+DONKw0y3J9xr3AvQC7d++euxnrJ2G8uC9US6bGlhXl/PefX58VsU2VBpdFMuXIPWiVUNqjPjNd7/xR7FqX5ZMrcr9hUz03bKrjmg21PG8GeVSYefLfd/06/uXh4xxrH2TjsjJef8lyp1LmVFdG3CebXycfZUGfk9soDfp49zVrePc1ayZ935/esmla3zMbNFSF2VBfljVqGSw//mjbIA2VIW6/LLviZeOyMh76ixudm6+7+Zs3XjLl797WUMGy8uC0xN3v9eQ9LpqqwqyrK+WXr3Q529990VpVU8LP/+z6cReryVhfV8pvTnQ78yNNxD/+9mXTvrtV0OfB51Ek05o/m8ExcN2GOtbVlXK6eySrtBisC/iX3rWLDfVzEzTMSNyVUg1a6zbz9K2AXUnzAPBtpdTngUZgE7A3x0csGuxEaqYUcpGrO5l5ZqZLgyspmit5m4sbNlmRmL1dllWE8CgmrLZZY7rlIb8nZ1K5pjTAN99/tfMYMknLu69dw//91Uk6BmN87PateDyK1bUleD3KGdUJmRkhJ4rWCp0vvn1HzlHIdWVBTnaN8LHbt47r2QFOqeXFoJTi/devm9Wo8rbtK7j316co8XspD/myggBgQpsqHxvNb52KuE82CDEXSimqSgKsryvNssemisejeNfVq/mH/z6as6Q0XznqbDDpGa6U+g5wE1CnlGoB/idwk1JqB5Ytcwb4AIDW+ohS6vvAy0AS+KDWevHd1txFPFVYkfvFUBGyovCpJlMB3n7lat5+ZeZ5WdDHf77/ai6d4ER05uioDE96sbQTafYo0PKQnw+9bjMPHW7jt0yJWtDnZfeaap442slfm/I9525WM8g9FAr5rLPrNtZRVeLnLZc35nx9tvjAazZMvtI0+O2dTXz5lyd56Eg7122szVmZNF1+Z1cTTVUhLls5s4BnKvz7/9iVNchpuvzuFav40YHWGQdlM2Uq1TJ35Vj8lQnW/zTw6Ytp1HwythRysXnus4lSius21o2bsna65Er8ummoDBMwUxpMRu2YyB3g/dev4/3XZyc3b9u+gk/97GVOdQ2zvr7MGdk3XVumGLDvDVBobFpezqWNFRy5MOjYaxdLScDHLVun54NPl91TzFPko7LEz4MfumGWWjN1ZITqIk+ozjb33b17zsXB61HsXlvtzJ8zEe5qmYmwu68PmWHsvznRTW1pYMYVLMLCYJc5Xj6HkbZgMdNqmaLBEXe7FHLJX+5mh2//4TVTWs9dLTMRjVVha46Sw+2877p1PHmsk7fsaLzoQWfC/PKOq1YzEks5pZnC3LHkpcyZWyaxNCL3xcbWFeV88OYNzhD1iXjTZSs42DLA//fgUUbiqTlNRglzQ1nQx4det2nKo16FmbPkxT02NnIXcZ9XfF4PH7l1a9YIxXzcfe1atiwv5/5nz1Ie8mVNtyoIQjYi7gVW576UCfm9/O937iTo8/CGbSvy3qxEEIQl7rm7b+EWL6A696XM5uXlPPQXNxZ1fbsgzAZLWtztm0iAFcFL1F4YTHXqBEFYyizpfm3cded0S9xF3QVBKA6Wtrgn3eKeEnEXBKFoEHF3PRZtFwShWBBxtx+nxJYRBKF4WNrinsrMaab1xd9iTxAEYbGwpMU9mkhnPZfAXRCEYmFJi7u7WgZkdKogCMXD0hb35FhxX6CGCIIgzDIi7i4kchcEoVgQcXchUw8IglAsLG1xH+e5L1BDBEEQZplJxV0p9VWlVKdS6rBrWY1S6lGl1Anzv9osV0qpf1VKNSulDimlds1l4y8WsWUEQShWphK5fx24bcyyjwGPa603AY+b5wC3A5vM3z3Al2enmXPD2Gl+JXIXBKFYmFTctda/BnrHLL4DuN88vh+407X8G9riOaBKKdUwS22ddeybYpcGrMkxZ+Nu7IIgCIuBmXruy7XWbeZxO2DffrwJOO9ar8UsG4dS6h6l1D6l1L6urq4ZNuPisG/UURK0bvkltowgCMXCRSdUtdYa0JOuOP5992qtd2utd9fX119sM2aEnVAtDZrIXbRdEIQiYabi3mHbLeZ/p1neCqxyrbfSLJt3EmMqYXJhe+4lAYncBUEoLmYq7g8A7zGP3wP81LX8blM1cw0w4LJv5o3zvRG2/d1DHG4dmHC9eDKNz6MIeK3NINouCEKxMJVSyO8AzwJblFItSqn3A/8EvF4pdQJ4nXkO8CBwCmgG7gP+ZE5aPQktfaMkUprmzuEJ14sn0wR8HvxG3CVyFwShWJj0Hqpa67vyvPTaHOtq4IMX26iLJWqqYHpH4hOuF0+JuAuCUJwU5QjVaNwS977IJOKeTBP0efB5LVEXbRcEoVgoTnGfYuQeM7aMzyORuyAIxUVxiru5CcdUIveA10PAZ4m6pyi3hiAIS5GilLNoYjqRu9eJ3L0SuQuCUCQUpbiPGnHvG0lMuJ6dUM147iLugiAUB0Up7rYt0zupLZMi6PXgdzz3OW+aIAjCvFCU4h5zIvc4VnVmbuw6dztyl4SqIAjFQlGKu23LJNOaoVgy73pS5y4IQrFSlOJuJ1TBit7zYde5+6XOXRCEIqNIxT0zadhEFTNOnbtE7oIgFBlFKu6uyH2CpKpd5+73SJ27IAjFRVHK2WgiRU1pAIDeCcohZeIwQRCKlaIU91giTUNlCJjccxdbRhCEYqQoxT2aTFFXFsTvVRPWusecahm7FHK+WigIgjC3FKe4J1KE/V6qSwJ5I3ettVUt4/Xg80iduyAIxUVRivtoIkXI76GmNJC3WiaRsgY3BXwe/D77Tkwi7oIgFAeT3qyjEIkm0oTsyD2PLfNKxxAAKyrDpNOW0IstIwhCsXBRkbtS6oxS6iWl1ItKqX1mWY1S6lGl1Anzv3p2mjp1ookUIb+XpuowzZ3Djni7+cXhNrwexS1bl8n0A4IgFB2zYcvcrLXeobXebZ5/DHhca70JeNw8n1diJnK/dn0tfZEER9sHx63z0OF2rl5XQ01pIFMtU5QmlSAIS5G5kLM7gPvN4/uBO+fgO/KSSmviqTQhv4frNtYB8ExzT9Y6zZ1DnOwa4fbtKwAIyJS/giAUGRcr7hp4RCm1Xyl1j1m2XGvdZh63A8tzvVEpdY9Sap9Sal9XV9dFNiODPTo15PeyojLEhvpSnj7ZnbXOw0c6AHjDpZa4y232BEEoNi5W3K/XWu8Cbgc+qJS60f2itubbzTnnrtb6Xq31bq317vr6+otsRgZH3E0FzHUb69hzqpd4MjPfzLH2IVbXlLC8whro5JM6d0EQioyLEnetdav53wn8GLgK6FBKNQCY/50X28jpEDUiHg54AXj1hjpGEylePN/vrHOhf5SmqrDz3J5+QG6zJwhCsTBjcVdKlSqlyu3HwBuAw8ADwHvMau8BfnqxjZwOo/GMLQOwa3UVAMdcSdXWvlGaqjPibg9iEs9dEIRi4WLq3JcDPzaC6AO+rbV+SCn1PPB9pdT7gbPA7118MyendyTOfb85xesuWQZA0GeJe315kKDPw/neCGDNJ9MxFKXRHbn75DZ7giAUFzMWd631KeDyHMt7gNdeTKNmwj/94ijf39dC0Ah1yJ8ZdbqqpoRzRtzbB6JoDSvd4i4JVUEQioyiqOw+1NLPf+1vAeBcjyXiYWPLAKyuKeFc7ygALf3W61m2jFfmcxcEobgoCjn73COvUFNizd9+pmcEyHjuAKuqw7T0RtBa09pniXx2QlU8d0EQiouiEPeXWgd4w6UrqAz7OWsi9yxxrylhKJakP5LgQn8UgIaqkPN65mYd89hoQRCEOaTgxX1gNEHvSJx1dSUsrwjSY2aBtD13sGwZgPN9EVr7IywrDzoJV0Bu1iEIQtFR8OJ+ptuyYdbWljqDkiDbc19lxP1cb4TW/tGsShkgcw9VEXdBEIqEwhd347Gvq8sW92A+cR9T4w4SuQuCUHwUvLif6hpBKUvAV7jE3W3LlAV91JQGONcT4UJ/NKsMEpDb7AmCUHQUvLif6RmhsTJMyO9leUUQAKUg4M3+aatqSvjvl9qIp9KsqyvNes1JqIq6C4JQJBS+uHePOGJt2zJhv3dcWeOGulKGoknedfVq7tzZlPVaZvqBeWiwIAjCPFDQt9nTWnO6e4S37GgEMuLuLoO0+dgbt/K+69exvaly3GteSagKglBkFLS490USDEaTrK21IvcVlUbcfeM7JMvKQywrD41bDtbgpes31nFpY8XcNVYQBGEeKWhxP92dqZQBqC0N4FG5I/fJ+M8/uHpW2yYIgrCQFLTnftaUQa414u7zeqgvD85I3AVBEIqJgo7c37qzies31lFbFnSWLa8IOQlSQRCEpUpBi7tSimUV2T76B2/eiM55Yz9BEISlQ0GLey5uNTe9FgRBWMoUtOcuCIIg5EbEXRAEoQiZM3FXSt2mlDqulGpWSn1srr5HEARBGM+ciLtSygt8Cbgd2AbcpZTaNhffJQiCIIxnriL3q4BmrfUprXUc+C5wxxx9lyAIgjCGuRL3JuC863mLWeaglLpHKbVPKbWvq6trjpohCIKwNFmwhKrW+l6t9W6t9e76+vqFaoYgCEJRMlfi3gqscj1faZYJgiAI84DSczCcUynlA14BXosl6s8D79RaH8mzfhdwdoZfVwd0z/C9c81ibZu0a3os1nbB4m2btGt6zLRda7TWOa2PORmhqrVOKqX+FHgY8AJfzSfsZv0Z+zJKqX1a690zff9csljbJu2aHou1XbB42ybtmh5z0a45m35Aa/0g8OBcfb4gCIKQHxmhKgiCUIQUg7jfu9ANmIDF2jZp1/RYrO2Cxds2adf0mPV2zUlCVRAEQVhYiiFyFwRBEMYg4i4IglCEFLS4L5aZJ5VSq5RSTyqlXlZKHVFKfcgs/6RSqlUp9aL5e+MCtO2MUuol8/37zLIapdSjSqkT5n/1ArRri2u7vKiUGlRK/cVCbDOl1FeVUp1KqcOuZTm3kbL4V3PMHVJK7Zrndv2LUuqY+e4fK6WqzPK1SqlR13b793luV979ppT6uNlex5VSt85VuyZo2/dc7TqjlHrRLJ/PbZZPI+buONNaF+QfVv38SWA9EAAOAtsWqC0NwC7zuBxrANc24JPAXy3wdjoD1I1Z9hngY+bxx4B/XgT7sh1YsxDbDLgR2AUcnmwbAW8EfgEo4Bpgzzy36w2Azzz+Z1e71rrXW4DtlXO/mfPgIBAE1plz1jufbRvz+ueAv1uAbZZPI+bsOCvkyH3RzDyptW7TWh8wj4eAo4yZKG2RcQdwv3l8P3DnwjUFsEYyn9Raz3SU8kWhtf410Dtmcb5tdAfwDW3xHFCllGqYr3ZprR/RWifN0+ewpvaYV/Jsr3zcAXxXax3TWp8GmrHO3Xlvm1JKAb8HfGeuvj8fE2jEnB1nhSzuk848uRAopdYCO4E9ZtGfmm7VVxfC/gA08IhSar9S6h6zbLnWus08bgeWL0C73LyD7BNuobcZ5N9Gi+m4ex9WdGezTin1glLqV0qpGxagPbn222LaXjcAHVrrE65l877NxmjEnB1nhSzuiw6lVBnwQ+AvtNaDwJeBDcAOoA2rSzjfXK+13oV145QPKqVudL+orT7ggtXDKqUCwFuA/zKLFsM2y2Kht1EulFKfAJLAt8yiNmC11non8GHg20qpinls0qLbbzm4i+wgYt63WQ6NcJjt46yQxX1RzTyplPJj7bRvaa1/BKC17tBap7TWaeA+5rA7mg+tdav53wn82LShw+7imf+d890uF7cDB7TWHbA4tpkh3zZa8ONOKfX7wJuBdxlBwNgePebxfixve/N8tWmC/bbg2wucyQx/G/ievWy+t1kujWAOj7NCFvfngU1KqXUm+nsH8MBCNMR4eV8BjmqtP+9a7vbI3gocHvveOW5XqVKq3H6MlYw7jLWd3mNWew/w0/ls1xiyoqmF3mYu8m2jB4C7TTXDNcCAq1s95yilbgM+CrxFax1xLa9X1u0tUUqtBzYBp+axXfn22wPAO5RSQaXUOtOuvfPVLhevA45prVvsBfO5zfJpBHN5nM1Hpniu/rAyyq9gXXE/sYDtuB6rO3UIeNH8vRH4JvCSWf4A0DDP7VqPValwEDhibyOgFngcOAE8BtQs0HYrBXqASteyed9mWBeXNiCB5W2+P982wqpe+JI55l4Cds9zu5qxvFj7OPt3s+7vmH38InAA+K15blfe/QZ8wmyv48Dt870vzfKvA380Zt353Gb5NGLOjjOZfkAQBKEIKWRbRhAEQciDiLsgCEIRIuIuCIJQhIi4C4IgFCEi7oIgCEWIiLsgCEIRIuIuCIJQhPz/ARCr9jrGVaYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/RL5_exercise6.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "config = {'observation_space': cartpole.observation_space.shape[0],\n",
    "          'nb_actions': cartpole.action_space.n,\n",
    "          'learning_rate': 0.001,\n",
    "          'gamma': 0.95,\n",
    "          'buffer_size': 1000000,\n",
    "          'epsilon_min': 0.01,\n",
    "          'epsilon_max': 1.,\n",
    "          'epsilon_decay_period': 1000,\n",
    "          'epsilon_delay_decay': 20,\n",
    "          'batch_size': 20}\n",
    "\n",
    "agent = DQN_agent(config, DQN)\n",
    "scores = agent.train(cartpole, 200)\n",
    "plt.plot(scores)\n",
    "\n",
    "x = cartpole.reset()\n",
    "#cartpole.render()\n",
    "for i in range(1000):\n",
    "    a = greedy_action(DQN, x)\n",
    "    y, _, d, _ = cartpole.step(a)\n",
    "    #cartpole.render()\n",
    "    x=y\n",
    "    if d:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "cartpole.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=sec5></a>Making DQN more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec5.1></a>Changing the optimizer\n",
    "\n",
    "The question of which optimizer to choose is quite open in RL. Most common choices are RMSprop or Adam (with, sometimes, carefully chosen hyperparameters). For the example of CartPole, it seems Adam with default parameters works better, but that's not a general rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec5.2></a>Several gradient steps\n",
    "\n",
    "Recall that within an iteration of Value Iteration, one aims at minimizing the $L_n(\\theta)$ (before moving on to the next iteration). Why take a single gradient step on this loss when a new sample is collected? Taking several gradient steps can greatly accelerate the convergence in terms of number of collected samples. That's what is commonly called *sample efficiency*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec5.3></a>Target network\n",
    "\n",
    "It appears the code above will (probably) slowly converge to $Q^*$ but this convergence might be unstable and noisy. This can be greatly improved by taking several gradient steps on a given loss function $L_n$ instead of changing the loss function after each sample. This idea is similar to the one above. And is the same as that of delayed updates that we introduced in the class on temporal difference learning. \n",
    "\n",
    "In practice, this is achieved by the introduction of a *target network* whose parameters are noted $\\theta^-$. This idea for DQN was introduced in the **[Human-level control through deep reinforcement learning](https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning)** paper. At any time step, the loss becomes:\n",
    "$$L(\\theta) = \\mathbb{E}_{s,a,r,s'} \\left[ \\left( r + \\gamma \\max_{a'} Q(s',a',\\theta^-) - Q(s,a;\\theta) \\right) ^2 \\right],$$\n",
    "and the target network parameters $\\theta^-$ are only updated with the Q-network parameters $\\theta_n$ every $C$ steps and are held fixed between individual updates.\n",
    "\n",
    "This process of accumulating several gradient steps into $\\theta_n$ before updating $\\theta^-$ draws our algorithm closer to a Value Iteration scheme (or a Fitted Q-Iteration scheme for that matter).\n",
    "\n",
    "Note that more recent approaches smooth out this accumulation process by defining soft updates of the form:\n",
    "$$\\theta^- \\leftarrow \\beta \\theta^- + (1-\\beta) \\theta_n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=sec5.4></a>Error clipping\n",
    "\n",
    "Another common pratice to stabilize learning is to clip the value of the loss' gradient between $-1$ and $1$. This is not such an uncommon trick, it actually amounts to using an L2 loss for values of the loss between $-1$ and $1$ and an L1 loss outside of this domain. This is also know as the [Huber Loss](https://en.wikipedia.org/wiki/Huber_loss) or the [smooth L1 loss](https://pytorch.org/docs/stable/nn.html#smoothl1loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Modify you code from the previous exercises to include a target network (with $C$ in the order of $100$), a fixed number of gradient steps per acquired sample, and the clipping of the error term. You can also use Adam for improved efficiency.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL5_exercise7.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "class DQN_agent:\n",
    "    def __init__(self, config, model):\n",
    "        self.gamma = config['gamma']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.nb_actions = config['nb_actions']\n",
    "        self.memory = ReplayBuffer(config['buffer_size'])\n",
    "        self.epsilon_max = config['epsilon_max']\n",
    "        self.epsilon_min = config['epsilon_min']\n",
    "        self.epsilon_stop = config['epsilon_decay_period']\n",
    "        self.epsilon_delay = config['epsilon_delay_decay']\n",
    "        self.epsilon_step = (self.epsilon_max-self.epsilon_min)/self.epsilon_stop\n",
    "        self.nb_gradient_steps = config['gradient_steps'] # NEW NEW NEW\n",
    "        self.total_steps = 0\n",
    "        self.model = model \n",
    "        self.criterion = torch.nn.SmoothL1Loss() # NEW NEW NEW\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config['learning_rate']) # NEW NEW NEW\n",
    "        self.target_model = deepcopy(self.model).to(device) # NEW NEW NEW\n",
    "        self.update_target_freq = config['update_target_freq'] # NEW NEW NEW\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
    "            QYmax = self.target_model(Y).max(1)[0].detach()\n",
    "            update = torch.addcmul(R, self.gamma, 1-D, QYmax)\n",
    "            QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
    "            loss = self.criterion(QXA, update.unsqueeze(1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def train(self, env, max_episode):\n",
    "        episode_return = []\n",
    "        episode = 0\n",
    "        episode_cum_reward = 0\n",
    "        state = env.reset()\n",
    "        epsilon = self.epsilon_max\n",
    "        step = 0\n",
    "        while episode < max_episode:\n",
    "            # update epsilon\n",
    "            if step > self.epsilon_delay:\n",
    "                epsilon = max(self.epsilon_min, epsilon-self.epsilon_step)\n",
    "\n",
    "            # select epsilon-greedy action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.randint(self.nb_actions)\n",
    "            else:\n",
    "                action = greedy_action(self.model, state)\n",
    "\n",
    "            # step\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            self.memory.append(state, action, reward, next_state, done)\n",
    "            episode_cum_reward += reward\n",
    "\n",
    "            # train\n",
    "            for _ in range(self.nb_gradient_steps): # NEW NEW NEW\n",
    "                self.gradient_step()\n",
    "\n",
    "            # update target network if needed\n",
    "            if step % self.update_target_freq == 0: # NEW NEW NEW\n",
    "                self.target_model.load_state_dict(self.model.state_dict())   \n",
    "            \n",
    "            # next transition\n",
    "            step += 1\n",
    "            if done:\n",
    "                episode += 1\n",
    "                print(\"Episode \", '{:3d}'.format(episode), \n",
    "                      \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                      \", batch size \", '{:5d}'.format(len(self.memory)), \n",
    "                      \", episode return \", '{:4.1f}'.format(episode_cum_reward),\n",
    "                      sep='')\n",
    "                state = env.reset()\n",
    "                episode_return.append(episode_cum_reward)\n",
    "                episode_cum_reward = 0\n",
    "            else:\n",
    "                state = next_state\n",
    "\n",
    "        return episode_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Run your code to learn an efficient policy for CartPole. Don't forget to reset the network before you start learning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode   1, epsilon   1.00, batch size    25, episode return 25.0\n",
      "Episode   2, epsilon   0.97, batch size    53, episode return 28.0\n",
      "Episode   3, epsilon   0.95, batch size    69, episode return 16.0\n",
      "Episode   4, epsilon   0.92, batch size   100, episode return 31.0\n",
      "Episode   5, epsilon   0.90, batch size   117, episode return 17.0\n",
      "Episode   6, epsilon   0.89, batch size   131, episode return 14.0\n",
      "Episode   7, epsilon   0.88, batch size   146, episode return 15.0\n",
      "Episode   8, epsilon   0.86, batch size   166, episode return 20.0\n",
      "Episode   9, epsilon   0.84, batch size   180, episode return 14.0\n",
      "Episode  10, epsilon   0.81, batch size   212, episode return 32.0\n",
      "Episode  11, epsilon   0.79, batch size   235, episode return 23.0\n",
      "Episode  12, epsilon   0.78, batch size   243, episode return  8.0\n",
      "Episode  13, epsilon   0.75, batch size   278, episode return 35.0\n",
      "Episode  14, epsilon   0.73, batch size   292, episode return 14.0\n",
      "Episode  15, epsilon   0.72, batch size   303, episode return 11.0\n",
      "Episode  16, epsilon   0.70, batch size   319, episode return 16.0\n",
      "Episode  17, epsilon   0.69, batch size   331, episode return 12.0\n",
      "Episode  18, epsilon   0.68, batch size   344, episode return 13.0\n",
      "Episode  19, epsilon   0.67, batch size   355, episode return 11.0\n",
      "Episode  20, epsilon   0.66, batch size   365, episode return 10.0\n",
      "Episode  21, epsilon   0.65, batch size   379, episode return 14.0\n",
      "Episode  22, epsilon   0.64, batch size   388, episode return  9.0\n",
      "Episode  23, epsilon   0.62, batch size   404, episode return 16.0\n",
      "Episode  24, epsilon   0.60, batch size   422, episode return 18.0\n",
      "Episode  25, epsilon   0.60, batch size   430, episode return  8.0\n",
      "Episode  26, epsilon   0.58, batch size   447, episode return 17.0\n",
      "Episode  27, epsilon   0.56, batch size   461, episode return 14.0\n",
      "Episode  28, epsilon   0.55, batch size   471, episode return 10.0\n",
      "Episode  29, epsilon   0.54, batch size   482, episode return 11.0\n",
      "Episode  30, epsilon   0.53, batch size   493, episode return 11.0\n",
      "Episode  31, epsilon   0.52, batch size   504, episode return 11.0\n",
      "Episode  32, epsilon   0.51, batch size   516, episode return 12.0\n",
      "Episode  33, epsilon   0.50, batch size   527, episode return 11.0\n",
      "Episode  34, epsilon   0.48, batch size   545, episode return 18.0\n",
      "Episode  35, epsilon   0.47, batch size   560, episode return 15.0\n",
      "Episode  36, epsilon   0.44, batch size   584, episode return 24.0\n",
      "Episode  37, epsilon   0.41, batch size   614, episode return 30.0\n",
      "Episode  38, epsilon   0.34, batch size   683, episode return 69.0\n",
      "Episode  39, epsilon   0.28, batch size   753, episode return 70.0\n",
      "Episode  40, epsilon   0.24, batch size   789, episode return 36.0\n",
      "Episode  41, epsilon   0.21, batch size   815, episode return 26.0\n",
      "Episode  42, epsilon   0.18, batch size   848, episode return 33.0\n",
      "Episode  43, epsilon   0.13, batch size   904, episode return 56.0\n",
      "Episode  44, epsilon   0.10, batch size   926, episode return 22.0\n",
      "Episode  45, epsilon   0.08, batch size   952, episode return 26.0\n",
      "Episode  46, epsilon   0.03, batch size   997, episode return 45.0\n",
      "Episode  47, epsilon   0.01, batch size  1016, episode return 19.0\n",
      "Episode  48, epsilon   0.01, batch size  1037, episode return 21.0\n",
      "Episode  49, epsilon   0.01, batch size  1081, episode return 44.0\n",
      "Episode  50, epsilon   0.01, batch size  1153, episode return 72.0\n",
      "49\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/RL5_exercise8.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Let's reset the Q function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "\n",
    "cartpole = gym.make('CartPole-v1')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "state_dim = cartpole.observation_space.shape[0]\n",
    "n_action = cartpole.action_space.n \n",
    "nb_neurons=24\n",
    "\n",
    "# reset the Q function\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)\n",
    "\n",
    "# config\n",
    "config = {'observation_space': cartpole.observation_space.shape[0],\n",
    "          'nb_actions': cartpole.action_space.n,\n",
    "          'learning_rate': 0.001,\n",
    "          'gamma': 0.95,\n",
    "          'buffer_size': 1000000,\n",
    "          'epsilon_min': 0.01,\n",
    "          'epsilon_max': 1.,\n",
    "          'epsilon_decay_period': 1000,\n",
    "          'epsilon_delay_decay': 20,\n",
    "          'batch_size': 20,\n",
    "          'gradient_steps': 10,\n",
    "          'update_target_freq': 100}\n",
    "\n",
    "# dqn agent\n",
    "agent = DQN_agent(config, DQN)\n",
    "scores = agent.train(cartpole, 50)\n",
    "\n",
    "plt.plot(scores);\n",
    "torch.save(DQN.state_dict(), \"cart_pole_dqn.pth\")\n",
    "\n",
    "DQN.load_state_dict(torch.load(\"cart_pole_dqn.pth\"))\n",
    "x = cartpole.reset()\n",
    "#cartpole.render()\n",
    "for i in range(1000):\n",
    "    a = greedy_action(DQN, x)\n",
    "    y, _, d, _ = cartpole.step(a)\n",
    "    #cartpole.render()\n",
    "    x=y\n",
    "    if d:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "cartpole.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec6\"></a> Metrics\n",
    "\n",
    "Let's take a step back to reflect about what we really measure in the experiment above. We have counted the number of steps per training episode. But during these episodes, the applied policy was $\\epsilon$-greedy, not greedy. So this is not an objective measure of performance.\n",
    "\n",
    "On the other hand, what is really being optimized here is the average sum of discounted rewards.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Enhance your previous code with the monitoring, after each episode, of:\n",
    "- the number of steps of the training episode\n",
    "- a Monte Carlo estimate of the total sum of rewards from the (distribution of) starting state,\n",
    "- a Monte Carlo estimate of the sum of discounted rewards from the (distribution of) starting state,\n",
    "- an average, over possible starting states $s_0$ of the current $\\max_a Q(s_0,a)$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL5_exercise9.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "class DQN_agent:\n",
    "    def __init__(self, config, model):\n",
    "        self.gamma = config['gamma']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.nb_actions = config['nb_actions']\n",
    "        self.memory = ReplayBuffer(config['buffer_size'])\n",
    "        self.epsilon_max = config['epsilon_max']\n",
    "        self.epsilon_min = config['epsilon_min']\n",
    "        self.epsilon_stop = config['epsilon_decay_period']\n",
    "        self.epsilon_delay = config['epsilon_delay_decay']\n",
    "        self.epsilon_step = (self.epsilon_max-self.epsilon_min)/self.epsilon_stop\n",
    "        self.nb_gradient_steps = config['gradient_steps']\n",
    "        self.nb_trials = config['nb_trials'] # NEW NEW NEW\n",
    "        self.total_steps = 0\n",
    "        self.model = model \n",
    "        self.criterion = torch.nn.SmoothL1Loss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config['learning_rate'])\n",
    "        self.target_model = deepcopy(self.model).to(device)\n",
    "        self.update_target_freq = config['update_target_freq']\n",
    "\n",
    "    def MC_eval(self, env, nb_trials):  # NEW NEW NEW\n",
    "        MC_total_reward = []\n",
    "        MC_discounted_reward = []\n",
    "        for _ in range(nb_trials):\n",
    "            x = cartpole.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            discounted_reward = 0\n",
    "            step = 0\n",
    "            while not done:\n",
    "                a = greedy_action(self.model, x)\n",
    "                y,r,done,_ = cartpole.step(a)\n",
    "                x = y\n",
    "                total_reward += r\n",
    "                discounted_reward += self.gamma**step * r\n",
    "                step += 1\n",
    "            MC_total_reward.append(total_reward)\n",
    "            MC_discounted_reward.append(discounted_reward)\n",
    "        return np.mean(MC_discounted_reward), np.mean(MC_total_reward)\n",
    "    \n",
    "    def eval_init_state(self, env, nb_trials):   # NEW NEW NEW\n",
    "        with torch.no_grad():\n",
    "            for _ in range(nb_trials):\n",
    "                val = []\n",
    "                x = env.reset()\n",
    "                val.append(self.model(torch.Tensor(x).unsqueeze(0).to(device)).max().item())\n",
    "        return np.mean(val)\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
    "            QYmax = self.target_model(Y).max(1)[0].detach()\n",
    "            update = torch.addcmul(R, self.gamma, 1-D, QYmax)\n",
    "            QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
    "            loss = self.criterion(QXA, update.unsqueeze(1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    \n",
    "    def train(self, env, max_episode):\n",
    "        # Training monitoring\n",
    "        episode_return = []\n",
    "        MC_avg_total_reward = []   # NEW NEW NEW\n",
    "        MC_avg_discounted_reward = []   # NEW NEW NEW\n",
    "        avg_Q_init_state = []   # NEW NE W NEW\n",
    "        \n",
    "        # Initialization\n",
    "        episode = 0\n",
    "        episode_cum_reward = 0\n",
    "        state = env.reset()\n",
    "        epsilon = self.epsilon_max\n",
    "        step = 0\n",
    "        while episode < max_episode:\n",
    "            # update epsilon\n",
    "            if step > self.epsilon_delay:\n",
    "                epsilon = max(self.epsilon_min, epsilon-self.epsilon_step)\n",
    "\n",
    "            # select epsilon-greedy action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.randint(self.nb_actions)\n",
    "            else:\n",
    "                action = greedy_action(self.model, state)\n",
    "\n",
    "            # step\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            self.memory.append(state, action, reward, next_state, done)\n",
    "            episode_cum_reward += reward\n",
    "\n",
    "            # train\n",
    "            for _ in range(self.nb_gradient_steps):\n",
    "                self.gradient_step()\n",
    "\n",
    "            # update target network if needed\n",
    "            if step % self.update_target_freq == 0:\n",
    "                self.target_model.load_state_dict(self.model.state_dict())   \n",
    "            \n",
    "            # next transition\n",
    "            step += 1\n",
    "            if done:\n",
    "                episode += 1\n",
    "                \n",
    "                # Monitoring\n",
    "                if self.nb_trials>0:\n",
    "                    MC_dr, MC_tr = self.MC_eval(env, self.nb_trials)    # NEW NEW NEW\n",
    "                    Q0 = self.eval_init_state(env, self.nb_trials)   # NEW NEW NEW\n",
    "                    MC_avg_total_reward.append(MC_tr)   # NEW NEW NEW\n",
    "                    MC_avg_discounted_reward.append(MC_dr)   # NEW NEW NEW\n",
    "                    avg_Q_init_state.append(Q0)   # NEW NEW NEW\n",
    "                    episode_return.append(episode_cum_reward)   # NEW NEW NEW\n",
    "                    print(\"Episode \", '{:2d}'.format(episode), \n",
    "                          \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                          \", batch size \", '{:4d}'.format(len(self.memory)), \n",
    "                          \", ep return \", '{:4.1f}'.format(episode_cum_reward), \n",
    "                          \", MC tot \", '{:6.2f}'.format(MC_tr),\n",
    "                          \", MC disc \", '{:6.2f}'.format(MC_dr),\n",
    "                          \", Q0 \", '{:6.2f}'.format(Q0),\n",
    "                          sep='')\n",
    "                else:\n",
    "                    episode_return.append(episode_cum_reward)\n",
    "                    print(\"Episode \", '{:2d}'.format(episode), \n",
    "                          \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                          \", batch size \", '{:4d}'.format(len(self.memory)), \n",
    "                          \", ep return \", '{:4.1f}'.format(episode_cum_reward), \n",
    "                          sep='')\n",
    "                \n",
    "                # Start new episode\n",
    "                state = env.reset()\n",
    "                episode_cum_reward = 0\n",
    "            else:\n",
    "                state = next_state\n",
    "\n",
    "        return episode_return, MC_avg_discounted_reward, MC_avg_total_reward, avg_Q_init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Use this monitoring to plot these values versus the number of episodes, after training.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  1, epsilon   1.00, batch size   14, ep return 14.0, MC tot  10.32, MC disc   8.20, Q0   0.07\n",
      "Episode  2, epsilon   1.00, batch size   25, ep return 11.0, MC tot  10.88, MC disc   8.53, Q0   0.32\n",
      "Episode  3, epsilon   0.95, batch size   68, ep return 43.0, MC tot  12.80, MC disc   9.54, Q0   1.05\n",
      "Episode  4, epsilon   0.94, batch size   80, ep return 12.0, MC tot  16.18, MC disc  10.96, Q0   1.07\n",
      "Episode  5, epsilon   0.93, batch size   93, ep return 13.0, MC tot  20.08, MC disc  12.19, Q0   1.07\n",
      "Episode  6, epsilon   0.90, batch size  121, ep return 28.0, MC tot   9.44, MC disc   7.67, Q0   1.97\n",
      "Episode  7, epsilon   0.87, batch size  148, ep return 27.0, MC tot  20.42, MC disc  12.83, Q0   2.01\n",
      "Episode  8, epsilon   0.84, batch size  180, ep return 32.0, MC tot  19.72, MC disc  12.61, Q0   1.97\n",
      "Episode  9, epsilon   0.83, batch size  194, ep return 14.0, MC tot  18.54, MC disc  12.16, Q0   2.03\n",
      "Episode 10, epsilon   0.80, batch size  227, ep return 33.0, MC tot  23.76, MC disc  13.95, Q0   2.94\n",
      "Episode 11, epsilon   0.75, batch size  275, ep return 48.0, MC tot  17.32, MC disc  11.67, Q0   2.93\n",
      "Episode 12, epsilon   0.73, batch size  292, ep return 17.0, MC tot  20.26, MC disc  12.81, Q0   3.00\n",
      "Episode 13, epsilon   0.70, batch size  326, ep return 34.0, MC tot  82.64, MC disc  19.70, Q0   3.71\n",
      "Episode 14, epsilon   0.62, batch size  408, ep return 82.0, MC tot 147.10, MC disc  19.99, Q0   4.67\n",
      "Episode 15, epsilon   0.52, batch size  510, ep return 102.0, MC tot 126.06, MC disc  19.93, Q0   5.50\n",
      "Episode 16, epsilon   0.43, batch size  592, ep return 82.0, MC tot 165.56, MC disc  19.98, Q0   5.53\n",
      "Episode 17, epsilon   0.39, batch size  639, ep return 47.0, MC tot 166.78, MC disc  19.98, Q0   6.30\n",
      "Episode 18, epsilon   0.28, batch size  751, ep return 112.0, MC tot 177.14, MC disc  19.99, Q0   6.98\n",
      "Episode 19, epsilon   0.24, batch size  788, ep return 37.0, MC tot 111.04, MC disc  19.90, Q0   7.11\n",
      "Episode 20, epsilon   0.06, batch size  971, ep return 183.0, MC tot 128.86, MC disc  19.97, Q0   8.39\n",
      "Episode 21, epsilon   0.01, batch size 1100, ep return 129.0, MC tot 126.34, MC disc  19.96, Q0   8.91\n",
      "Episode 22, epsilon   0.01, batch size 1260, ep return 160.0, MC tot 201.40, MC disc  19.99, Q0  10.10\n",
      "Episode 23, epsilon   0.01, batch size 1448, ep return 188.0, MC tot 269.72, MC disc  20.00, Q0  11.21\n",
      "Episode 24, epsilon   0.01, batch size 1643, ep return 195.0, MC tot 295.20, MC disc  20.00, Q0  12.22\n",
      "Episode 25, epsilon   0.01, batch size 1817, ep return 174.0, MC tot 157.40, MC disc  19.99, Q0  13.05\n",
      "Episode 26, epsilon   0.01, batch size 1985, ep return 168.0, MC tot 227.76, MC disc  20.00, Q0  13.29\n",
      "Episode 27, epsilon   0.01, batch size 2166, ep return 181.0, MC tot 160.78, MC disc  19.98, Q0  14.12\n",
      "Episode 28, epsilon   0.01, batch size 2318, ep return 152.0, MC tot 120.52, MC disc  19.96, Q0  14.68\n",
      "Episode 29, epsilon   0.01, batch size 2479, ep return 161.0, MC tot 123.88, MC disc  19.96, Q0  14.92\n",
      "Episode 30, epsilon   0.01, batch size 2615, ep return 136.0, MC tot 154.00, MC disc  19.99, Q0  15.55\n",
      "Episode 31, epsilon   0.01, batch size 2754, ep return 139.0, MC tot 166.54, MC disc  19.99, Q0  15.85\n",
      "Episode 32, epsilon   0.01, batch size 2915, ep return 161.0, MC tot 135.42, MC disc  19.98, Q0  16.33\n",
      "Episode 33, epsilon   0.01, batch size 3136, ep return 221.0, MC tot 144.44, MC disc  19.99, Q0  16.53\n",
      "Episode 34, epsilon   0.01, batch size 3269, ep return 133.0, MC tot 160.12, MC disc  19.99, Q0  16.68\n",
      "Episode 35, epsilon   0.01, batch size 3397, ep return 128.0, MC tot 163.72, MC disc  19.99, Q0  16.97\n",
      "Episode 36, epsilon   0.01, batch size 3549, ep return 152.0, MC tot 161.74, MC disc  19.99, Q0  17.15\n",
      "Episode 37, epsilon   0.01, batch size 3731, ep return 182.0, MC tot 135.32, MC disc  19.97, Q0  17.54\n",
      "Episode 38, epsilon   0.01, batch size 3927, ep return 196.0, MC tot 129.20, MC disc  19.97, Q0  17.66\n",
      "Episode 39, epsilon   0.01, batch size 4085, ep return 158.0, MC tot 230.84, MC disc  20.00, Q0  17.90\n",
      "Episode 40, epsilon   0.01, batch size 4354, ep return 269.0, MC tot 234.80, MC disc  20.00, Q0  18.34\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/RL5_exercise10.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Let's reset the Q function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "state_dim = cartpole.observation_space.shape[0]\n",
    "n_action = cartpole.action_space.n \n",
    "nb_neurons=24\n",
    "\n",
    "DQN = torch.nn.Sequential(nn.Linear(state_dim, nb_neurons),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(nb_neurons, nb_neurons),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(nb_neurons, n_action)).to(device)\n",
    "\n",
    "config = {'observation_space': cartpole.observation_space.shape[0],\n",
    "          'nb_actions': cartpole.action_space.n,\n",
    "          'learning_rate': 0.001,\n",
    "          'gamma': 0.95,\n",
    "          'buffer_size': 1000000,\n",
    "          'epsilon_min': 0.01,\n",
    "          'epsilon_max': 1.,\n",
    "          'epsilon_decay_period': 1000,\n",
    "          'epsilon_delay_decay': 20,\n",
    "          'batch_size': 20,\n",
    "          'gradient_steps': 10,\n",
    "          'update_target_freq': 100,\n",
    "          'nb_trials': 50}\n",
    "\n",
    "agent = DQN_agent(config, DQN)\n",
    "ep_length, disc_rewards, tot_rewards, Q0 = agent.train(cartpole, 40)\n",
    "\n",
    "plt.plot(ep_length, label=\"training episode length\")\n",
    "plt.plot(tot_rewards, label=\"MC eval of total reward\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(disc_rewards, label=\"MC eval of discounted reward\")\n",
    "plt.plot(Q0, label=\"average $max_a Q(s_0)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks on CartPole:\n",
    "- Have you noted that Q overestimates the true value of the optimal policy? More on this in [this paper](https://papers.nips.cc/paper/3964-double-q-learning) if you are interested.\n",
    "- Have you noted that the greedy policy is optimal much sooner than the $Q$ function?\n",
    "- Have you remarked that the greedy policy performs well much sooner than the agent's policy (which is $\\epsilon$-greedy)?\n",
    "- Can you anticipate the importance of well tuned exploration, for instance if the state space is much larger, or if parts of it are very hard to reach?\n",
    "- Can you anticipate the effect of taking a larger $\\gamma$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Train on SwingUp.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/.local/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  1, epsilon   0.90, batch size  198, ep return -10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/reinforcement-learning/notebooks/environments/swingup.py:32: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  2, epsilon   0.74, batch size  359, ep return -10.0\n",
      "Episode  3, epsilon   0.50, batch size  606, ep return -10.0\n",
      "Episode  4, epsilon   0.43, batch size  673, ep return -10.0\n",
      "Episode  5, epsilon   0.31, batch size  793, ep return -10.0\n",
      "Episode  6, epsilon   0.26, batch size  844, ep return -10.0\n",
      "Episode  7, epsilon   0.22, batch size  886, ep return -10.0\n",
      "Episode  8, epsilon   0.17, batch size  936, ep return -10.0\n",
      "Episode  9, epsilon   0.13, batch size  981, ep return -10.0\n",
      "Episode 10, epsilon   0.04, batch size 1075, ep return -10.0\n",
      "Episode 11, epsilon   0.01, batch size 1119, ep return -10.0\n",
      "Episode 12, epsilon   0.01, batch size 1164, ep return -10.0\n",
      "Episode 13, epsilon   0.01, batch size 1532, ep return 21.0\n",
      "Episode 14, epsilon   0.01, batch size 1579, ep return -10.0\n",
      "Episode 15, epsilon   0.01, batch size 1733, ep return -10.0\n",
      "Episode 16, epsilon   0.01, batch size 1788, ep return -10.0\n",
      "Episode 17, epsilon   0.01, batch size 1844, ep return -10.0\n",
      "Episode 18, epsilon   0.01, batch size 2017, ep return -10.0\n",
      "Episode 19, epsilon   0.01, batch size 2075, ep return -10.0\n",
      "Episode 20, epsilon   0.01, batch size 2123, ep return -10.0\n",
      "Episode 21, epsilon   0.01, batch size 2225, ep return -10.0\n",
      "Episode 22, epsilon   0.01, batch size 2283, ep return -10.0\n",
      "Episode 23, epsilon   0.01, batch size 2392, ep return -10.0\n",
      "Episode 24, epsilon   0.01, batch size 2728, ep return -10.0\n",
      "Episode 25, epsilon   0.01, batch size 3205, ep return 36.0\n",
      "Episode 26, epsilon   0.01, batch size 3296, ep return -10.0\n",
      "Episode 27, epsilon   0.01, batch size 3559, ep return 27.0\n",
      "Episode 28, epsilon   0.01, batch size 3656, ep return -10.0\n",
      "Episode 29, epsilon   0.01, batch size 3740, ep return -10.0\n",
      "Episode 30, epsilon   0.01, batch size 3805, ep return -10.0\n",
      "177\n",
      "-10.0\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/RL5_exercise11.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Let's reset the Q function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from environments.swingup import CartPoleSwingUp\n",
    "\n",
    "swingup = CartPoleSwingUp()\n",
    "\n",
    "config = {'observation_space': swingup.observation_space.shape[0],\n",
    "          'nb_actions': swingup.action_space.n,\n",
    "          'learning_rate': 0.001,\n",
    "          'gamma': 0.95,\n",
    "          'buffer_size': 1000000,\n",
    "          'epsilon_min': 0.01,\n",
    "          'epsilon_max': 1.,\n",
    "          'epsilon_stop': 10000,\n",
    "          'epsilon_decay_period':1000,\n",
    "          'epsilon_delay_decay': 100,\n",
    "          'batch_size': 20,\n",
    "          'gradient_steps': 10,\n",
    "          'update_target_freq': 100,\n",
    "          'nb_trials': 0}\n",
    "\n",
    "DQN = torch.nn.Sequential(nn.Linear(swingup.observation_space.shape[0], 24),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(24, 24),\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(24, swingup.action_space.n)).to(device)\n",
    "\n",
    "agent = DQN_agent(config, DQN)\n",
    "ep_length, disc_rewards, tot_rewards, Q0 = agent.train(swingup, 30)\n",
    "torch.save(DQN.state_dict(), \"swingup_dqn.pth\")\n",
    "\n",
    "DQN.load_state_dict(torch.load(\"swingup_dqn.pth\"))\n",
    "x = swingup.reset()\n",
    "#swingup.render()\n",
    "tot_rew = 0\n",
    "for i in range(1000):\n",
    "    a = greedy_action(DQN, x)\n",
    "    y, r, d, _ = swingup.step(a)\n",
    "    #swingup.render()\n",
    "    x=y\n",
    "    tot_rew += r\n",
    "    if d:\n",
    "        break\n",
    "\n",
    "print(i)\n",
    "print(tot_rew)\n",
    "\n",
    "#swingup.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks on SwingUp:\n",
    "- Did your DQN learn to avoid the -10 penalty instead of swinging up? The exploration question becomes a crucial issue, doesn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec7\"></a>DQN on image-based tasks\n",
    "\n",
    "Now it's time to turn towards Pong. As you noted earlier, the frame information in Pong is not sufficient to define an MDP, but stacking several frames together allows to recover the Markov property.\n",
    "\n",
    "We could wish to modify the previous replay buffer so that frames are stored only once (for memory efficiency). Then this new replay buffer would still need to return stacks of 4 frames when `sample()` is called.\n",
    "\n",
    "Fortunately, there's a simpler way to do that.\n",
    "We can use a wrapper (provided by Gym in this case) so that calling env.step(a) returns a stack of 4 frames.\n",
    "This wrapper actually only stores each frame once which optimizes memory efficiency. This way, we can keep on using our previous replay buffer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import FrameStack\n",
    "pong = FrameStack(pong, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pong.reset()\n",
    "print(torch.Tensor(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two DQN papers ([Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602) and [Human-level control through deep reinforcement learning](https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning)) actually introduce two different neural network architectures.\n",
    "\n",
    "The 2013 paper uses this architecture:\n",
    "- input: $84\\times 84\\times 4$ image (the last 4 frames)\n",
    "- layer 1: Convolutions with 16 filters of size $8\\times 8$ and stride 4. The activation is a ReLU function.\n",
    "- layer 2: Convolutions with 32 filters of size $4\\times 4$ and stride 2. The activation is a ReLU function.\n",
    "- layer 3: Fully connected with 256 ReLU units\n",
    "- layer 4 (output): Fully connected with 2 linear units (one for each action's value)\n",
    "\n",
    "The 2015 paper \n",
    "- input: $84\\times 84\\times 4$ image (the last 4 frames)\n",
    "- layer 1: Convolutions with 32 filters of size $8\\times 8$ and stride 4. The activation is a ReLU function.\n",
    "- layer 2: Convolutions with 64 filters of size $4\\times 4$ and stride 2. The activation is a ReLU function.\n",
    "- layer 3: Convolutions with 64 filters of size $3\\times 3$ and stride 1. The activation is a ReLU function.\n",
    "- layer 4: Fully connected with 512 ReLU units\n",
    "- layer 5 (output): Fully connected with 2 linear units (one for each action's value)\n",
    "\n",
    "Also, it is a good practice to pre-fill the replay buffer with randomly sampled experience. The 2015 paper runs a random policy for 50000 steps to feed the replay buffer before training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:** Create the corresponding neural network and adapt your optimization code from the previous exercice to train on Pong (you can take $C$ much larger, in the order of $10000$).\n",
    "</div>\n",
    "\n",
    "Caveat: unless you have a good GPU and a fair amount of time ahead of you (several hours or more), it is recommended to run this computation for a limited number of episodes, on a cloud computing service (or on a dediated machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 50000/50000 [01:21<00:00, 616.74it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2673/4271651509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mep_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2673/4183550076.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, max_episode)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_gradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# update target network if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2673/4183550076.py\u001b[0m in \u001b[0;36mgradient_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mQYmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQYmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mQXA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatland-rl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2673/4271651509.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# %load solutions/RL5_exercise12.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Let's reset the Q function\n",
    "\n",
    "class AtariCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4, n_actions=2):\n",
    "        super(AtariCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.head = nn.Linear(512, n_actions)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
    "        return self.head(x)\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "config = {'observation_space': cartpole.observation_space.shape[0],\n",
    "          'nb_actions': cartpole.action_space.n,\n",
    "          'learning_rate': 0.001,\n",
    "          'gamma': 0.95,\n",
    "          'buffer_size': 1000000,\n",
    "          'epsilon_min': 0.1,\n",
    "          'epsilon_max': 1.,\n",
    "          'epsilon_stop': 1000000,\n",
    "          'epsilon_delay_decay': 0,\n",
    "          'epsilon_decay_period':1000,\n",
    "          'batch_size': 32,\n",
    "          'gradient_steps': 10,\n",
    "          'update_target_freq': 10000,\n",
    "          'nb_trials': 0}\n",
    "\n",
    "AtariDQN = AtariCNN()\n",
    "\n",
    "agent = DQN_agent(config, AtariDQN)\n",
    "\n",
    "# pre-fill the replay buffer\n",
    "x = pong.reset()\n",
    "for t in trange(50000):\n",
    "    a = np.random.randint(2)\n",
    "    y, r, d, _ = pong.step(a)\n",
    "    agent.memory.append(x, a, r, y, d)\n",
    "    if d:\n",
    "        x = pong.reset()\n",
    "    else:\n",
    "        x = y\n",
    "\n",
    "# train\n",
    "ep_length, disc_rewards, tot_rewards, Q0 = agent.train(pong, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you an idea of the behavior of a trained agent, you can check the following videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"p88R2_3yWPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo(\"TmPfTpjtdgg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec7\"></a>Going further\n",
    "\n",
    "A lot of contributions have built on the initial success of DQN. Among those, some are combined and discussed in the **[Rainbow: Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298)** paper. We will simply summarize their key ideas here, by decreasing order of importance (according to the paper).\n",
    "\n",
    "- N-step returns. Use samples that accumulate several returns rather than the 1-step return of TD(0).\n",
    "- [Prioritized experience replay](https://arxiv.org/abs/1511.05952). Inspired by the model-based [Prioritized Sweeping](https://link.springer.com/article/10.1007/BF00993104) approach, bias the distribution used to sample mini-batches in order to present high residual samples to the optimizer. Prioritized Sweeping is designed to accelerate the convergence in $L_\\infty$ norm for tabular representations.\n",
    "- [Distributional value functions](https://arxiv.org/abs/1707.06887). Instead of estimating $\\mathbb{E}(\\sum_t \\gamma^t r_t)$, estimate the distribution of $\\sum_t \\gamma^r r_t$ and iterate on it.\n",
    "- [NoisyNet](https://arxiv.org/abs/1706.10295). Instead of an $\\epsilon$-greedy exploration strategy, introduce noise in the network's parameters to drive the exploration.\n",
    "- [Dueling architecture](https://arxiv.org/abs/1511.06581). The neural network's architecture splits $Q$ into the estimation of a value $V(s)$ and an advantage $A(s,a)$ with shared first layers.\n",
    "- [Double Q-learning](https://arxiv.org/abs/1509.06461). Q-learning is prone to over-estimation of the true optimal Q function (especially in high variance environments). Double Q-learning aims at compensating this weakness by introducing an under-estimation mechanism based on a second Q function.\n",
    "\n",
    "Beyond these improvements, new work is published each year that leads to a better understanding of the interplay between Deep Learning and RL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"challenge\"></a>Challenge\n",
    "\n",
    "In this challenge, we provide two new environments, on top of the SwingUp problem introduced before. All environments feature different difficulties. It is recommended that you focus on a single environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"bicycle\"></a>Bicycle\n",
    "\n",
    "This environment was originally introduced in the 1998 article on **[Learning to Drive a Bicycle Using Reinforcement Learning and Shaping](#https://www.researchgate.net/publication/221346431_Learning_to_Drive_a_Bicycle_Using_Reinforcement_Learning_and_Shaping)** by J. Randløv and P. Alstrøm. Notably, it was also one of the key benchmarks for **[Least Squares Policy Iteration](http://www.jmlr.org/papers/volume4/lagoudakis03a/lagoudakis03a.pdf)** by Lagoudakis and Parr in 2003.\n",
    "\n",
    "The environment provided here uses the exact same simulator but defines more rigorously the state variables. It is not a gym environment and has no `render` method, but it still provides the `step` and `reset` methods.\n",
    "\n",
    "In short, in this environment you try to ride a bicyle from an initial location $(x,y)=(0,0)$ to a goal that is located one kilometer further $(x_{goal},y_{goal})=(1000,0)$.\n",
    "\n",
    "The bicycle state variables are:\n",
    "- $\\theta$ the angle of the handlebar\n",
    "- $\\dot{\\theta}$\n",
    "- $\\omega$ the tilt angle between the $z$-axis and the bicycle+cyclist center of mass\n",
    "- $\\dot{\\omega}$\n",
    "- $x_b,y_b$ the position of the bicyle's back tire\n",
    "- $x_f,y_f$ the position of the bicyle's front tire\n",
    "- $\\psi'_{goal}$ a not-so-useful variable kept for historical reasons, that is roughly proprotional to $\\psi_{goal}$\n",
    "- $d_{goal}$ the distance between the front tire and the goal\n",
    "- $\\psi$ the bicycle's heading angle (angle between the bicycle and the y-axis)\n",
    "- $\\psi_{goal}$ the angle between the bicycle back wheel - front wheel axis, and the back wheel - goal axis\n",
    "\n",
    "The agent starts at $(x_b,y_b)=(0,0)$ with a random heading in $[-\\pi,\\pi]$, and random small values for $\\theta$, $\\dot{\\theta}$, $\\omega$ and $\\dot{\\omega}$ around the unstable equilibrium point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.bicycle import Bicycle\n",
    "bike = Bicycle()\n",
    "x = bike.reset()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cyclist moves at a constant speed and his actions to control the bicycle consist in applying a torque to the handlebar or shifting his weight left or right. The action space is discrete and consists of 5 actions. What you pass to the `step` method is the action index.\n",
    "\n",
    "The episode ends when the tilt angle exceeds $\\frac{\\pi}{15}$.\n",
    "\n",
    "To encourage the bike staying up and guiding it towards the goal, the reward model uses *reward shaping*. It is written:\n",
    "$$r(s,a,s') = \\omega^2 - \\omega'^2 + k\\cdot\\left( d_{goal} - d'_{goal} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(bike.action_set)\n",
    "X = []\n",
    "x = bike.reset()\n",
    "X.append(x)\n",
    "for i in range(1000):\n",
    "    y, r, d, _ = bike.step(0)\n",
    "    x = y\n",
    "    X.append(x)\n",
    "    if d:\n",
    "        break\n",
    "\n",
    "print(\"trajectory length\", len(X))\n",
    "X = np.array(X)\n",
    "plt.plot(X[:,4],X[:,5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sti\"></a>Structured Treatment Interruptions\n",
    "\n",
    "This environment implements the simulator defined in **[Dynamic Multidrug Therapies for HIV: Optimal and STI Control Approaches](https://www.aimspress.com/fileOther/PDF/MBE/1551-0018_2004_2_223.pdf)** by B. M. Adams et al. (2004). It was notably used in **[Clinical data based optimal STI strategies for HIV: a reinforcement learning approach](https://ieeexplore.ieee.org/document/4177178)** by D. Ernst et al. (2006).\n",
    "\n",
    "This environment simulates the immune system of an HIV-infected patient. It is not a gym environment and has no `render` method, but it still provides the `step` and `reset` methods. \n",
    "\n",
    "In short, HIV can infect two types of cells (type 1 and type 2 below) and replicate itself, which increases the virus load in the blood stream. The immune system fights off the virus by increasing the concentration of macrophages (effector cells below).\n",
    "\n",
    "The patient state variables are:\n",
    "- $T_1$ healthy type 1 cells concentration (cells per mL)\n",
    "- $T_1^*$ infected type 1 cells concentration (cells per mL)\n",
    "- $T_2$ healthy type 2 cells concentration (cells per mL)\n",
    "- $T_2^*$ infected type 2 cells concentration (cells per mL)\n",
    "- $V$ free virus (copies per mL)\n",
    "- $E$ immune effector cells concentration (cells per mL)\n",
    "\n",
    "Once infected, if no treatment is applied, the patient naturally evolve to one of two steady states: either the immune system controls the infection and the patient is healthy, or the infection dominates and the patient is unhealthy.\n",
    "\n",
    "By default `reset` deterministically puts the patient in the infected unhealthy state.\n",
    "\n",
    "    The transition() function allows to simulate continuous time dynamics and control.\n",
    "    The step() function is tailored for the evaluation of Structured Treatment Interruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.hiv_patient import HIVPatient\n",
    "patient = HIVPatient()\n",
    "print(\"Uninfected patient:\", patient.reset(\"uninfected\"))\n",
    "print(\"Unhealthy patient:\", patient.reset()) # actually equivalent to patient.reset(\"unhealthy\")\n",
    "print(\"Healthy patient:\", patient.reset(mode=\"healthy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `step` method simulates the evolution of the patient over a time step of $5$ days. The system is deterministic. For example, if we want to simulate a patient with a 25% immunity loss, with no treatment, over 400 days, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from environments.hiv_patient import HIVPatient\n",
    "\n",
    "patient = HIVPatient()\n",
    "s = patient.reset(mode=\"healthy\")\n",
    "s[5] *= .75\n",
    "patient.E *= .75\n",
    "print(patient.E)\n",
    "dur = 80 # 400/5\n",
    "#nb_steps = int(dur//1e-3)\n",
    "states = [s]\n",
    "for i in range(dur):\n",
    "    s, r, d, _ = patient.step(0)\n",
    "    states.append(s)\n",
    "    \n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 15))\n",
    "npst = np.array(states)\n",
    "axs[0,0].plot(npst[:,0])\n",
    "axs[0,0].set_title(\"T1\")\n",
    "axs[0,1].plot(npst[:,1])\n",
    "axs[0,1].set_title(\"T1*\")\n",
    "axs[0,2].plot(npst[:,2])\n",
    "axs[0,2].set_title(\"T2\")\n",
    "axs[1,0].plot(npst[:,3])\n",
    "axs[1,0].set_title(\"T2*\")\n",
    "axs[1,1].plot(npst[:,4])\n",
    "axs[1,1].set_title(\"V\")\n",
    "axs[1,2].plot(npst[:,5])\n",
    "axs[1,2].set_title(\"E\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of drugs can be given to the patient, that differ in the way they affect the viral load. The problem we look at consists in giving or not a certain drug at every step, to allow for **structured treatment interruptions** (STI). Such interruptions have double goal: train the immune system to react by itself and provide the patient with a better quality of life.\n",
    "\n",
    "The action space is discrete and consists of 5 actions. What you pass to the `step` method is the action index.\n",
    "\n",
    "The patient's death over the course of treatment is not explicitly modelled (but the viral load can reach very high values). So this simulator does not have a termination condition (`step` never returns `done=True`). The reward model discourages giving drugs, aims at a low viral load and a high immunity:\n",
    "$$r(s,a,s') = -k_V \\cdot V + k_E \\cdot E -k_1 R_2 - k_2 \\cdot R_2$$\n",
    "where $R_1$ and $R_2$ are the amounts of prescribed drugs 1 and 2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient.action_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"turn\"></a>Your turn to play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise (open-ended):**  \n",
    "Your turn to play!  \n",
    "Can you solve SwingUp? Bicycle? STI?  \n",
    "Why are these problems more difficult than CartPole?  \n",
    "Be creative!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
